# 2 Tue

## \[AI 스쿨 1기\] 12주차 DAY 2

### Recommendation system : 컨텐츠 기반 추천 엔진 개발

넷플릭스 프라이즈 개요

* 2006년부터 3년간 운영된 넷플릭스의 기념비적인 추천 엔진 경진대회
* 넷플릭스 추천 시스템 품질을 10% 개선하는 팀에게 $1M 수여 약속
  * RMSE가 평가 기준
* 넷플릭스 브랜드 인지도가 올라감
* 프라이버시 이슈도 제기됨
* 이를 기폭제로 캐글과 같은 머신러닝 경진대회 플랫폼이 등장

넷플릭스 프라이즈 우승팀과 알고리즘

* 이 대회를 통해 협업 필터링이 한단계 발전함
  * SVD를 활용
  * 앙상블 방식의 모델들이 가장 좋은 성능을 보임
    * 너무 긴 실행시간 때문에 실제로 사용하지는 못함
  * 다양한 알고리즘들이 논문으로 발표됨

앙상블과 랜덤 포레스트

* 모델을 하나만 이용하는 게 아니라 여러 모델을 이용해서 가장 많이 예측된 클래스를 선택
  * 평균이나 중앙값 또는 다수결 방식으로 결정
* 성능은 좋지만 훈련과 예측 시간이 오래 걸린다는 단점 존재

추천 엔진의 발전 역사

* 아마존이 아이템 기반 협업 필터링 논문 발표, 2001
* 넷플릭스 프라이즈, 2006-2009
  * 딥러닝이 추천엔진에 쓰일 수 있음을 증명
* 딥러닝이 컨텐츠 기반 음악 추천에 사용됨, 2010
* 딥러닝을 기반으로한 추천이 활기를 띠기 시작, 2016
  * 오토인코더 기반으로 복잡한 행렬 계산을 단순화하는 방식

유데미 추천 살펴보기

* 문제 정의 : 학생들에게 관심있을 만한 강의를 먼저 보여주는 것
* 추천 UI
  * 격자 기반
  * 다양한 추천 유닛들이 존재
    * 몇 개의 유닛을 어느 순서로 보여줄지 결졍 : 유닛 선택과 랭킹
    * 페이지 생성 시간과 사용자 만족도는 반비례. =&gt; 너무 많은 유닛은 역효과
* 온라인 강의 메타 데이터
  * 분류 체계 =&gt; 카테고리와 서브 카테고리
  * 태그 =&gt; 키워드
  * 강사가 태그와 분류 체계 선택해야함. 사람이 하지 않으면 굉장히 힘이 드는 일.
* 다양한 행동 기반 추천
  * 클릭, 구매, 소비 등

기본 아이디어

* 하이브리드 방식 추천
  * 협업 필터링, 사용자 행동 기반, 머신러닝 모델 기반
* 사용자별로 등록 확률을 기준으로 2천개의 탑 강의 목록 생성
  * 배치로 시작했다가 실시간 계산으로 변경
* 홈페이지에서의 추천은 조금 더 복잡
  * 유닛 후보 생성
  * 유닛 후보 랭킹
* 특정 강의 세부페이지에서 추천은 아이템 중심
  * Student also bought, 아이템 기반 협업 필터링
  * Frequently bought together, 별도의 co-occurrence 행렬 계산
  * 각 유닛에서의 강의 랭킹은 개인별 등록 확률로 결정

인기도 기반 추천 유닛 개발

* Cold Start 이슈가 존재하지 않음
* 인기도의 기준
  * 평점, 매출, 최다 판매
* 사용자 정보에 따라 확장 가능
  * 특정 지역 인기 아이템 추천
* 개인화 되어있지는 않음
* 아이템의 분류 체계 정보가 존재하면 쉽게 확장 가능
  * 특정 카테고리에서의 인기 아이템 추천
  * 분류체계를 가지면 굉장히 유리
* 인기도를 다른 기준으로 바꿔 다양한 추천 유닛 생성 가능
  * top courses, new courses
* 기타 Cold Start 이슈가 없는 추천 유닛
  * 현재 사용자들이 구매한 아이템
  * 현재 사용자들이 보고 있는 아이템



### Recommendation system : 유사도 측정

컨텐츠 기반 측정

* 평점 등이 아닌 아이템 자체로 판단
* EX
  * 영화 : 배우, 제목, 장르 등
  * 옷 : 모양, 재질 등
* 장점
  * 평점 등이 없어도 추천할 수 있음
* 단점
  * 유사한 영화가 아니라 시리즈 영화만을 추천할 수 있음
  * 실제로 아이템을 소비한 뒤 부정적인 평가를 받을 수 있음



다양한 유사도 측정 알고리즘

* 벡터들 간의 유사도를 판단하는 방법
  * 두 벡터간의 거리보다는 방향을 보고 유사도를 판단한다
  * 코사인 유사도 사용

![](../../.gitbook/assets/image%20%28274%29.png)

* 대표적인 유사도는 코사인 유사도와 피어슨 유사도 이다
  * 피어슨 유사도는 코사인 유사도의 개선 버전
  * 평점처럼 방향 뿐만 아니라 벡터 크기의 정규화가 중요하면 피어슨 유사도를 사용
* 피어슨 유사도
  * 먼저 벡터 A와 B의 값을 보정
  * EX\) A = { 3, 4, 5 }의 평균값 4를 구한 뒤 각 원소에서 빼서 A' = { -1, 0 , 1}을 구한다
  * 이 후의 계산은 코사인 유사도와 동일
  * 장점
    * 모든 벡터가 원점을 중심으로 이동되고 벡터간의 비교가 더 쉬워짐
      * 평점이라는 것은 정규화 되어있는 지표지만 이 평점을 매기는 사용자의 성격은 정규화되어 있지 않는데\(까다로운 사용자와 대충인 사용자\) 이까지 정규화 시키는 방법

텍스트를 행렬\(벡터\)로 표현하는 방법

* 원핫 인코딩 - Bag of Words\(카운트\)
  * stopword\(the, is, in, we, can, see\) 제외
  * 이 후 단어수 계산 =&gt; 단어별로 차원을 배정

```text
text = [
    'The sky is blue'
    'The sun is bright'
    'The sun in the sky is bright'
    'We can see the shining sun, the bright sun'
```

![](../../.gitbook/assets/image%20%28275%29.png)

* 원핫 인코딩 - Bag of Words\(TF-IDF\)
  * 앞서 카운트 방식은 자주 나오는 단어가 높은 가중치를 갖게 됨
  * 기본 아이디어
    * 한 문서에서 중요한 단어를 카운트하는것이 아니라 문서 전체를 보고 판단하자
    * 어떤 단어가 한 문서에서 자주 나오면 중요하지만 이 단어가 다른 문서들에서는 자주 나오지 않는다면 더 중요한 단어이다.
  * 점수 TF-IDF = TF\(t, d\) \* IDF\(t\)
    * TF\(t, d\) : 단어 t가 문서 d에서 몇번 나왔나
    * DF\(t\) : 단어 t가 전체 문서군에서 몇번 나왔나
    * IDF\(t\) : DF\(t\)의 역수
  * 문제점
    * 정확하게 동일한 단어가 나와야 유사도 계산이 이뤄짐
      * 동의어 처리가 안됨
    * 단어의 수가 늘어나고 아이템의 수가 늘어나면 계산이 오래걸림
    * 결국 워드 임베딩을 사용하는 것이 더 좋음
      * 아니면 LSA\(Latent Semantic Analysis\)를 사용해 차원을 축소해야 함

CountVectorizer

* 앞서 Bag of Words 카운팅 방식을 구현한 모듈
* 벡터로 표현이 되면 문서들간의 유사도 측정이 가능
* \[a-z\] 순으로 sorting

TfIdVectorizer

* 앞서 Bag of Words TF-IDF 방식을 구현한 모듈
* 이후 COSINE\_SIMILARITY를 이용해 문서간 유사도를 측정



















