# 24 Wed

## \(부록\) 서울시 코로나19 발생현황 데이터 수집

### \[1/7\] 서울시 코로나 발생현황 데이터 수집 준비하기

데이터 수집 vs 크롤링

* 데이터 수집 : 웹사이트의 내용을 읽어오는 것, 스크래핑
* 크롤링 : 검색엔진이 하이퍼링크를 타고 웹 페이지의 내용을 읽어가는 것

필요 도구 설치

`request` : 작은 브라우저로 웹사이트를 읽어오는 목적

`beautifulsoup4` : 읽어온 웹 사이트를 해석하는 목적

`tqdm` : 여러 페이지를 읽어올 때 진행 상태를 확인하는 목적

* 오래걸리면서 반복되는 작업을 할 때 사용하면 좋다.



### \[2/7\] 데이터 수집 전 로봇배제표준, 저작권, 무리한 네트워크 요청 확인하기

수집해도 되는 페이지인지 확인하기

* 로봇 배제 표준 robots.txt
  * 웹 사이트에 로봇이 접근하는 것을 방지하기 위한 규약
  * 권고안이며, 접근 방지 설정을 하더라도 다른 사람들이 접근할 수 있다.
* 저작권
* 무리한 네트워크 요청

서울시 사이트 robots.txt 확인하기

![](../../.gitbook/assets/image%20%28310%29.png)

* 가져가도 된다고 허용되어 있음
* 사이트 맵도 볼 수 있다

네이버  사이트 robots.txt 확인하기

```markup
User-agent: *
Disallow: /
Allow : /$ 
```

* 구글에서 검색이 잘 안되는 이유는 `/` 루트 경로 이하의 모든 정보를 거부했기 때문
* `/$` 는 메인 페이지는 읽어도 된다는 뜻

저작권 확인하기

* 서울시는 공공누리 저작권
  * 별도의 허락없이 자유 이용이 가능하다

무리한 네트워크 요청

* 여러 페이지를 한 번에 읽어오면 DDOS 공격으로 의심받을 수 있다.
  * 따라서 time.sleep\(\) 으로 간격을 두고 가져온다.

데이터 수집 방법

1. 수집 하고자 하는 페이지의 URL을 알아본다
2. 파이썬의 작은 브라우저 requests를 통해 URL에 접근한다.
3. response.status\_code가 200 OK라면 정상 응답
4. request의 response값에서 response.txt만 받아온다.
5. html 텍스트를 bs\(response.txt, 'html.parse'\)로 해석한다.
6. soup.select를 통해 원하는 태그에 접근한다.
7. 목록을 받아온다.
8. 목록에서 행을 받아온다.
9. 행을 모아 데이터프레임으로 만든다.

데이터의 위치

* 개발자 코드로 소스 코드를 보면 html 태그에 해당 내용이 있지만 read\_html로 읽어올 수 없다.

### \[3/7\] 브라우저의 네트워크탭과 JSON 파일형식 이해하기

데이터 수집

* 보통 보이지 않는 데이터를 수집하기 위해 셀레니움을 사용
* 브라우저 동작 원리를 알면 셀레니움을 사용하지 않아도 수집 가능
* 개발자 도구 - Network - XHR - URL - Preview 순서를 통해 JSON 타입으로 데이터를 확인할 수 있다.

JSON

* 제이슨, JavaScript Object Notation
* 속성-값 쌍또는 키-값 쌍으로 이루어진 데이터 오브젝트를 전달하기 위해 사용하는 개방형 표준 포맷
* 프로그래밍 언어나 플랫폼에 독립적이어서 수많은 프로그래밍 언어에서 사용할 수 있다.
* 파이썬의 판다스도 JSON을 읽고 쓸 수 있다.

서울 코로나 발생현황 데이터 수집 순서

1. 페이지별 데이터 수집
2. 전체 페이지 수집
   * 1번을 반복문을 통해서 진행
3. `pd.concat` 으로 데이터를 하나로 병합
4. 데이터 전처리 =&gt; html 태그 제거
5. `to_csv` 로 전체 데이터 병합
6. `pd.read_csv` 로 데이터가 잘 저장되었는지 읽어와서 확인
7. 수집 끝, 분석 시작



### \[4/7\] 기존의 read\_html 로 데이터를 읽어올 수 없는 이유와 기존의 수집방법

\[5/7\] 네트워크 탭을 보는 방법과 수집할 URL 찾고 요청하기

\[6/7\] 전체 데이터를 수집하는 함수를 만들고 반복문으로 전체 데이터 수집하기

\[7/7\] 데이터 전처리와 저장하고 확인하기

