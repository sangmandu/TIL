# 29 Mon

## GARIGO : Face Mosaic Project

### 모델 인자 설정

#### face locations

```python
face_locations = face_recognition.face_locations(
    face, number_of_times_to_upsample=1, model='cnn')
```

* `number_of_times_to_upsample`
  * detect한 얼굴이 작으면 location 하는데 어려움이 있기 때문에 작은 얼굴들에 대해 upsample 할 수 있도록 했다.
  * detect도 하지 못할정도로 얼굴이 작은 경우의 문제는 쉽게 해결할 수 있는 부분은 아니다.
    * 차라리 tiny 모델을 써서 합성을 하는게 나을 정도.
    * 매번 모든 이미지를 확대 처리하기에는 너무 많은 자원이 들기 때문이다.
  * 이미지를 k배 확대할수록 시간도 k배 는다. 근데 그에 비해 성능이 k배 좋아지지는 않는다. 성능에 비해 시간이 너무 많이 소요되서 너무 작은 이미지에 대해서만 진행할 필요도 있다.
* `model='cnn'`
  * `cnn` 과 `hog` 버전이 있다.
  * cnn은 landmarks 68 방식을, hog는 landmarks 5 방식을 사용하며 tradeoff의 관계라고 생각하면 된다.

#### face encodings

```python
face_encodings = face_recognition.face_encodings(
    img_raw, face_locations, num_jitters=5, model="large")
```

* `num_jitters` 
  * encoding을 몇번에 반복해서 할 지 결정하는 인자이다.
    * 확실히는 모르겠지만, 좀 더 세밀하게 recognize 하는 것 같다.
  * upsample과 마찬가지로 k번 할수록 시간은 k배 는다. 하지만, 체감 시간이 그렇게 크지 않아서 5정도로 놓았다.
* `model='large'`
  * `small` 과 `large` 가 있다.
  * encoding 방식에 대한 부분이고 location에서  `cnn` 모델일 경우 encoding은 `large` 를 사용한다.
    * 주석이 default가 `large` 라고 하면서 실제 코드는 `small` 로 되어있다.

#### compare\_faces

```python
matches = face_recognition.compare_faces(
    known[person_name], face_encoding, tolerance=thresh)
```

* `tolerance`
  * 여기서는 스레시값을 고정해서 사용했는데, 각 신마다 다르게 할 필용성을 느낀다.
  * 두 얼굴간의 인코딩 값 차이가 일정 스레시 값 이하여야만 동일 얼굴로 판단한다.
    * 프로젝트에서는 0.45~0.6 정도가 적당했는데, 신마다 다르다.
    * 0.6은 종종 심하게 다른 인물을 동일 인물로 간주한다.

