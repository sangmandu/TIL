# 19 Wed

## \[동빈나 논문 분석\] [ResNet: Deep Residual Learning for Image Recognition](https://youtu.be/671BsKl8d0E)

### CVPR 2016

* 이해하기는 쉬우면서 성능을 높였기 때문에 매우 훌륭한 논문이다.
* 일반적인 CNN은 어느 시점 부터는 레이어가 깊어질 수록 성능이 더 안좋아졌는데 잔여 학습을 적용해서 해결할 수 있다고 제안했다.

### CNN 모델의 특징 맵

* 일반적으로 CNN에서 레이어가 깊어질 수록 채널의 수가 많아지고 너비와 높이는 줄어든다
* 컨볼루션 레이어의 서로 다른 필터들은 각각 적절한 특징값을 추출하도록 학습된다.

### VGG 네트워크

* ICLR 2015
* 3 x 3 컨볼루션 필터를 이용해 레이어의 깊이를 늘려 우수한 성능을 보인 모델
* 파라미터가 많다는 단점이 있지만 cnn의 특징을 잘 살려 현재까지도 백본 모델로 사용되고 있다는 장점이 있다

### 잔여 블록, Residual Block

* 잔여블록을 이용해 네트워크의 최적화 난이도를 낮추는 방법
* Plain layers
  * H\(x\) = F\(x\) 를 학습한다
* Residual layers
  * H\(x\) = x + F\(x\) 를 구해 F\(x\)를 학습한다











