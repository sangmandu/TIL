# 9 Tue

## PART 04 Computer Vision

### 01 CNN

Region Feature

* 신경망의 Input 변수는 독립적이어야 하는데 이미지는 주변 픽셀과의 지역성 때문에 독립적이지 못하다
* 이를 Flatten해서 사용하면 주변 픽셀과의 관련성을 알 수 없었고 따라서 이러한 지역 정보를 학습할 수 있는 신경망 구조가 필요했다 =&gt; 이것이 CNN
* graphical feature 이라고도 함

CNN

* Region Feature를 뽑아내는 Convolution Layer와 Feature Dimension을 위한 Pooling Layer와 최종적인 분류를 위한 Fully Connected Layer로 이루어져있다
* Convolution Layer
  * Receptive Field를 정의해 입력 층의 이미지의 Feature를 추출
  * Input이 20 x 20 이고 rec. field가 3 x 3 이면 feature는 18 x 18이다. 이 때 추출한 feature를 feature map 이라고 부른다.
  * stride는 rec. field가 feature를 뽑을 때 input 이미지 위에서 이동하는 칸수
  * padding은 feature의 크기가 원본 이미지의 크기와 동일할 수 있도록 추가하는 기법
  * weight sharing은 rec. field가 이미지에서 특징을 추출할 때 사용하는 가중치를 모두 동일한 가중치로 사용하도록 하는 기법 =&gt; 그렇지 않으면 파라미터의 수가 기하급수적으로 증가함
* Pooling Layer
  * Feature size를 반으로 줄여주는 것 \( 2 x2 stride max pooling 기준\)
  * CNN의 학습 속도를 향상시키기 위해 Feature의 Dimension을 줄이는 개념. =&gt; 정보 손실이 발생 =&gt; 최근에는 풀링이 잘 안쓰이는 추세. 더 많은 정보를 얻기 위해서 그리고 학습 속도를 높일 수 있는 알고리즘의 발전
  * 사각형 안의 최대 픽셀 값을 뽑으면 Max Pooling, 평균 픽셀 값을 뽑으면 Average Pooling
* Fully Connected Layer
  * MLP 구조와 동일
  * Feature를 Flatten시켜 MLP의 Input으로 놓고 학습을 진행

### 02 CNN & MLP

MLP는 이미지의 픽셀 값을 바로 Input으로 사용하는데 비해 CNN은 Convolution과 Pooling을 거친 Feature를 Input으로 사용한다.

컬러 이미지를 실험용 데이터로 쓸 때는 CIFAR-10과 ImageNet이 있지만 후자는 높은 수준의 컴퓨팅 파워가 필요해 전자를 주로 사용한다.

{% file src="../../.gitbook/assets/cifar\_10\_mlp.ipynb" caption="CIFAR-10\_MLP" %}

![](../../.gitbook/assets/image%20%28218%29.png)

최종적으로 47%의 정확도를 가졌다. 이는 흑백 손글씨의 90%의 정확도 수준과는 차이가 있다. 동일한 MLP 인데도 말이다. 차이가 나는 이유는 흑백과 컬러에 있다. 흑백 데이터는 MLP의 Input을 입력할 때 1차원으로 펴도 이미지의 특징을 덜 민감하게 사라지지만\(잘 사라지지 않는다\) 컬러 데이터는 이미지의 특징을 잃어버리는 것에 민감하기 때문.

{% file src="../../.gitbook/assets/cifar\_10\_cnn.ipynb" caption="CIFAR-10\_CNN" %}

![](../../.gitbook/assets/image%20%28125%29.png)

CNN으로 했더니 62%로 성능 향상!

