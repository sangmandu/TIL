# 5 Fri

## PART 02 AI Background

### 01 인공지능\(딥러닝\)의 정의와 사례

인공지능

* 인간의 지능으로 할 수 있는 사고 학습, 자기 개발 등을 컴퓨터가 할 수 있도록 하는 방법을 연구하는 컴퓨터 공학 및 정보 기술의 한 분야로, 컴퓨터가 인간의 지능적인 행동을 모방할 수 있도록 하는 것
* 컴퓨터가 데이터를 이용해 학습할 수 있도록 하는 기술

인공지능의 사례

* 이미지 분류
* 객체 탐지
* 텍스트
  * 기계 번역
  * 문장\(또는 문서\) 분류
  * 질의 응답 시스템
  * 개체명 인식
* 알파고
* GAN
  * Generative Adversarial Networks
* Style Transfer
  * 나의 사진을 고흐풍으로 바꿔주거나 낮 풍겨의 사진을 밤 풍경의 사진으로 바꿔주는 것
* Deepfake

### 02 파이토치

* 텐서플로우
  * 구글이 만들었고 파이토치보다 먼저 출시됨
  * 코드가 직관적이지 않고 디버깅이 어렵다
  * 이러한 단점을 보완하기 위해 2.0 버전 이상에서는 케라스를 이용해 가독성과 편의성을 제공
* 파이토치
  * 페이스북이 만들었다
  * 코드가 직관적이고 디버깅이 상대적으로 쉬우며 코드 커스텀이 쉽다

### 03 머신러닝의 정의와 종류

머신러닝과 인공지능

* 정의는 동일하지만 사용하는 분야가 다르다.
* 머신러닝은 행과 열이 존재하는 행렬을 이용해 예측 또는 분류를 할 때 사용
* 이미지와 텍스트 같은 정형화되어 있지 않은 데이터를 사용할 때는 인공지능\(딥러닝\)을 사용한다.
* 크게 보면 머신러닝은 인공지능 안에 포함되는 개념이지만 대중에게는 혼용해서 사용한다.

머신러닝의 종류

* 모델학습
  * 학습 목표는 데이터에 대한 모델의 결과가 정답에 가깝게 나오도록 학습시키는 것
* 손실 함수
  * 모델의 결과가 실제 정답과 어떤 차이가 있는지 수치화할 필요가 있다. 이 수치화된 차이를 함수화한 것을 `손실 함수` 또는 `비용 함수` 라고 한다.
  * 대표적으로는 Mean Squared Error\(MSE\)를 들 수 있다.

머선러닝의 구분

* 지도 학습
  * X로 Y를 예측하고 싶을 때 사용
  * 머신러닝을 통해  만든 예측 모델 f를 머신러닝 모델 이라고 한다.
  * X는 독립 변수 또는 Feature 라고 하며 Y는 종속 변수, 반응 변수, 타깃 변수 라고 한다.
  * 회귀문제와 분류문제가 있다
* 비지도 학습
  * 지도학습의 반대 개념
  * X변수만 존재하며 명확한 정답은 없다
  * 독립 변수만으로 새로운 Feature를 찾아내거나 군집화 하여 새로운 패턴을 찾아내는 것에 초점을 맞춘다.
  * 군집화, 차원 축소법 등이 있다.
* 강화 학습
  * 상태, 행동, 보상, 다음 상태의 4가지 개념이 존재
  * 수많은 시뮬레이션을 통해 현재 상태에서 어떤 행동을 취해야 먼 미래의 보상을 최대로 할 수 있는지 학습하는 알고리즘

지도학습 모델의 종류

* 선형 회귀 모델
  * 독립 변수 하나만으로 종속 변수를 예측 하는 모델을 단순 선형 회귀 모델이라고 한다
  * 변수가 여러 개일 때 적합시키는 회귀 모델을 다중 선형 회귀 모델이라고 한다.
* 회귀 계수 축소 모델
  * 변수가 너무 많으면 학습 데이터에 대한 성능을 높아지지만 비학습 데이터에 대한 성능은 낮아진다
  * 각각의 변수가 서로 연관성이 있을 때 변수의 해석력도 낮아진다. \(변수의 영향력이 생각보다 작아진다는 의미\)
  * 적절한 변수만 선택해 모델에 사용하는 것이 중요. 이 문제를 완화시켜주는 방법이 회귀 계수 축소 모델
  * Lasso : 회귀계수가 완전히 0이 되도록 축소시킬 수 있다
  * Ridge : 회귀계수가 0으로 가까워지긴 하지만 완전히 0이 되지 않는다
  * ElasticNet : Lasso와 Ridge의 중간 모델
* 의사 결정 나무

![](../../.gitbook/assets/image%20%28209%29.png)

* k-NN
  * 가장 가까운 k개의 데이터를 이용해 해당 데이터의 출력 값을 예측하는 직관적인 모델
  * k는 사용자가 사전에 지정해야 하는 하이퍼파라미터로 데이터 간 거리 측정 지표나 k개의 데이터의 정보를 종합하는 방법을 선택해 모델의 변화를 줄 수 있다
* 신경망
  * 딥러닝의 기초가 되는 모델
  * 학습에 사용된 데이터에만 완벽히 적합되는 과적합 문제 때문에 오랫동안 빛을 발휘하지 못했다
* SVM
  * Support Vector Machine
  * 신경망의 과적합에 대한 해결첵을 제시한 모델
  * 2010년대 초반까지 널리 쓰였지만 변수나 데이터 수가 많아질수록 학습하는 시간이 매우 오래 걸려 사용하지 않음
* Ensemble Learning
  * 다양한 모델을 만들어 여러 모델에 대해서 가장 좋은 예측 값을 선정
  * 데이터를 재구성해 모델을 만드는 Bagging
  * 데이터와 변수를 랜덤으로 추출해 모델을 만드는 RandomForest
  * 잘 맞추지 못하는 데이터를 좀 더 집중적으로 학습시키는 Boosting\(일반적으로 많이 쓰임\)
  * 여러 모델의 예측 값을 다시 독립 변수로 활용하는 Stacking\(시간이 오래 걸려 잘 쓰이지 않음\)

### 04 과적합

과적합이 발생하는 원인

* 본질적인 문제 : 샘플 데이터\(표본\)만 가지고 전체 데이터\(모집단\)를 예측하려고 하기 때문
* 학습할 샘플 데이터 수의 부족
* 풀고자 하는 문제에 비해 복잡한 모델을 적용
* 적합성 평가 및 실험 설계
  * 





## \[AI 스쿨 1기\] 9주차 DAY 5

### Big Data : ML Pipeline과 Tuning 소개





### Big Data : 범용 머신러닝 모델 파일 포맷 : PMML





### Big Data : 총정리







