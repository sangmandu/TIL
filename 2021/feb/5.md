# 5 Fri

## PART 02 AI Background

### 01 인공지능\(딥러닝\)의 정의와 사례

인공지능

* 인간의 지능으로 할 수 있는 사고 학습, 자기 개발 등을 컴퓨터가 할 수 있도록 하는 방법을 연구하는 컴퓨터 공학 및 정보 기술의 한 분야로, 컴퓨터가 인간의 지능적인 행동을 모방할 수 있도록 하는 것
* 컴퓨터가 데이터를 이용해 학습할 수 있도록 하는 기술

인공지능의 사례

* 이미지 분류
* 객체 탐지
* 텍스트
  * 기계 번역
  * 문장\(또는 문서\) 분류
  * 질의 응답 시스템
  * 개체명 인식
* 알파고
* GAN
  * Generative Adversarial Networks
* Style Transfer
  * 나의 사진을 고흐풍으로 바꿔주거나 낮 풍겨의 사진을 밤 풍경의 사진으로 바꿔주는 것
* Deepfake

### 02 파이토치

* 텐서플로우
  * 구글이 만들었고 파이토치보다 먼저 출시됨
  * 코드가 직관적이지 않고 디버깅이 어렵다
  * 이러한 단점을 보완하기 위해 2.0 버전 이상에서는 케라스를 이용해 가독성과 편의성을 제공
* 파이토치
  * 페이스북이 만들었다
  * 코드가 직관적이고 디버깅이 상대적으로 쉬우며 코드 커스텀이 쉽다

### 03 머신러닝의 정의와 종류

머신러닝과 인공지능

* 정의는 동일하지만 사용하는 분야가 다르다.
* 머신러닝은 행과 열이 존재하는 행렬을 이용해 예측 또는 분류를 할 때 사용
* 이미지와 텍스트 같은 정형화되어 있지 않은 데이터를 사용할 때는 인공지능\(딥러닝\)을 사용한다.
* 크게 보면 머신러닝은 인공지능 안에 포함되는 개념이지만 대중에게는 혼용해서 사용한다.

머신러닝의 종류

* 모델학습
  * 학습 목표는 데이터에 대한 모델의 결과가 정답에 가깝게 나오도록 학습시키는 것
* 손실 함수
  * 모델의 결과가 실제 정답과 어떤 차이가 있는지 수치화할 필요가 있다. 이 수치화된 차이를 함수화한 것을 `손실 함수` 또는 `비용 함수` 라고 한다.
  * 대표적으로는 Mean Squared Error\(MSE\)를 들 수 있다.

머선러닝의 구분

* 지도 학습
  * X로 Y를 예측하고 싶을 때 사용
  * 머신러닝을 통해  만든 예측 모델 f를 머신러닝 모델 이라고 한다.
  * X는 독립 변수 또는 Feature 라고 하며 Y는 종속 변수, 반응 변수, 타깃 변수 라고 한다.
  * 회귀문제와 분류문제가 있다
* 비지도 학습
  * 지도학습의 반대 개념
  * X변수만 존재하며 명확한 정답은 없다
  * 독립 변수만으로 새로운 Feature를 찾아내거나 군집화 하여 새로운 패턴을 찾아내는 것에 초점을 맞춘다.
  * 군집화, 차원 축소법 등이 있다.
* 강화 학습
  * 상태, 행동, 보상, 다음 상태의 4가지 개념이 존재
  * 수많은 시뮬레이션을 통해 현재 상태에서 어떤 행동을 취해야 먼 미래의 보상을 최대로 할 수 있는지 학습하는 알고리즘

지도학습 모델의 종류

* 선형 회귀 모델
  * 독립 변수 하나만으로 종속 변수를 예측 하는 모델을 단순 선형 회귀 모델이라고 한다
  * 변수가 여러 개일 때 적합시키는 회귀 모델을 다중 선형 회귀 모델이라고 한다.
* 회귀 계수 축소 모델
  * 변수가 너무 많으면 학습 데이터에 대한 성능을 높아지지만 비학습 데이터에 대한 성능은 낮아진다
  * 각각의 변수가 서로 연관성이 있을 때 변수의 해석력도 낮아진다. \(변수의 영향력이 생각보다 작아진다는 의미\)
  * 적절한 변수만 선택해 모델에 사용하는 것이 중요. 이 문제를 완화시켜주는 방법이 회귀 계수 축소 모델
  * Lasso : 회귀계수가 완전히 0이 되도록 축소시킬 수 있다
  * Ridge : 회귀계수가 0으로 가까워지긴 하지만 완전히 0이 되지 않는다
  * ElasticNet : Lasso와 Ridge의 중간 모델
* 의사 결정 나무

![](../../.gitbook/assets/image%20%28209%29.png)

* k-NN
  * 가장 가까운 k개의 데이터를 이용해 해당 데이터의 출력 값을 예측하는 직관적인 모델
  * k는 사용자가 사전에 지정해야 하는 하이퍼파라미터로 데이터 간 거리 측정 지표나 k개의 데이터의 정보를 종합하는 방법을 선택해 모델의 변화를 줄 수 있다
* 신경망
  * 딥러닝의 기초가 되는 모델
  * 학습에 사용된 데이터에만 완벽히 적합되는 과적합 문제 때문에 오랫동안 빛을 발휘하지 못했다
* SVM
  * Support Vector Machine
  * 신경망의 과적합에 대한 해결첵을 제시한 모델
  * 2010년대 초반까지 널리 쓰였지만 변수나 데이터 수가 많아질수록 학습하는 시간이 매우 오래 걸려 사용하지 않음
* Ensemble Learning
  * 다양한 모델을 만들어 여러 모델에 대해서 가장 좋은 예측 값을 선정
  * 데이터를 재구성해 모델을 만드는 Bagging
  * 데이터와 변수를 랜덤으로 추출해 모델을 만드는 RandomForest
  * 잘 맞추지 못하는 데이터를 좀 더 집중적으로 학습시키는 Boosting\(일반적으로 많이 쓰임\)
  * 여러 모델의 예측 값을 다시 독립 변수로 활용하는 Stacking\(시간이 오래 걸려 잘 쓰이지 않음\)

### 04 과적합

과적합이 발생하는 원인

* 본질적인 문제 : 샘플 데이터\(표본\)만 가지고 전체 데이터\(모집단\)를 예측하려고 하기 때문
* 학습할 샘플 데이터 수의 부족
* 풀고자 하는 문제에 비해 복잡한 모델을 적용
* 적합성 평가 및 실험 설계
  * 갖고 있는 데이터를 적절히 학습 데이터와 검증 데이터로 분할
  * 학습 데이터로 모델을 학습한 후 검증 데이터에 모델을 적용시켜 과적합 여부를 판단
  * 데이터 수가 적을 때는 검증데이터와 테스트 데이터 할당이 부담스러울 수 있다. 이 때는 K-Fold Croos Validation 기법을 사용한다.
    * 가지고 있는 데이터를 K개로 분할 해 각 데이터마다 1번을 검증, K-1번을 학습 데이터로 사용하여 평균적인 성능을 측정하는 방법







## \[AI 스쿨 1기\] 9주차 DAY 5

### Big Data : ML Pipeline과 Tuning 소개

Spark MLlib 모델 튜닝

* 최적의 하이퍼 파라미터 선택
  * 모델 밖에 있는 인자를 의미
  * 하나씩 테스트 하기 vs 다수를 동시에 테스트 하기
* 모델 테스트 방법
  * 교차 검증
  * 훈련/테스트셋 나누기

Spark MLlib 모델 테스트

* 훈련용과 테스트용 데이터 기반 테스트
  * 홀드아웃 테스트라고 하기도 함
  * 80 : 20 또는 75 : 25로 나눈다
* 교차분석 테스트
  * K-Fold 테스트 라고 부르기도 함
* 모델 선택시 입력
  * Estimator
    * 머신 러닝 알고리즘이나 모델 빙딩 파이프라인
  * Evaluator



### Big Data : 범용 머신러닝 모델 파일 포맷 : PMML

다양한 머신러닝 개발 플랫폼

* Scikit-Learn, PyTorch, Tensorflow, Spark MLlib
* 통용되는 머신러닝 파일포맷이 필요
  * PMML, MLeap이 대표적
* 머신러닝 모델 서빙환경의 통일이 가능
  * 실제로는 지원 기능이 미약해서 복잡한 모델의 경우에는 지원불가

PMML

* Predictive Model Markup Language
* 머신러닝 모델을 마크업 언어로 표현해주는 XML 언어
* 절차
  1. ML Pipeline을 PMML 파일로 저장
     * pyspark2pmml 파이썬 모듈이 필요
  2. PMML 파일을기반으로 모델 예측 API로 론치
  3. 이 API로 정보를 보내고 예측 결과를 받는 클라이언트 코드 작성





### Big Data : 총정리

Spark

* 차세대 분산 데이터 처리 프레임워크
* 정말 데이터가 클 때 사용

데이터 팀의 발전

* 서비스에서 직접 생기는 데이터와 써드파티를 통해 생기는 데이터를 데이터 웨어하우스에 저장
* 데이터 분석 =&gt; 지표 정의, 시각화
* 데이터 과학 적용







