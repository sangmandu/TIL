# 14 Sun

## \[인공지능을 위한 선형대수\] CHAPTER 4. 고유값 분해 <a id="ai-1-5-day-3"></a>

### 고유벡터와 고윳값

주어진 행렬 A가 정사각행렬이고 x가 영벡터가 아닐 때 $$ Ax = \lambda x $$를 만족하는 스칼라 lambda가 존재할 때 A를 고유벡터, lambda를 고윳값이라고 한다

![](../../.gitbook/assets/image%20%28278%29.png)

* Ax를 계산할 때 8번의 계산이 필요한데, 스칼라와 벡터곱은 2번의 연산이 필요하다
  * 학습시간을 빠르게 할 수 있음

식 변환

* 𝐴𝐱 = 𝜆𝐱
* 𝐴𝐱 - 𝜆𝐱 = 0
* 𝐴𝐱 − 𝜆𝐼 𝐱 = 𝟎
* \(𝐴 − 𝜆𝐼\)𝐱 = 𝟎
* 이 때 x는 영벡터가 아니라는 정의가 존재하므로 \(𝐴 − 𝜆𝐼\)는 선형종속적인 벡터가 된다.

### 영공간과 직교여공간

Ax = 0 일 때 이 식의 기하학적 의미는 A의 row vectors와 x의 column vector가 수직인 vector를 찾는 것

기본적으로 A의 Null Space는 \[0, 0\]이다.

선형 독립일 때 수직이라고는 할 수 없지만 수직이면 선형 독립이다.

직교 여공간

* 전체 스페이스를 어느 정도 양분하는 개념
* n 차원에서 A 벡터가 m개의 벡터를 구성하고 있다면 여공간은 n-m개의 벡터가 있다



### 특성방정식

\(𝐴 − 𝜆𝐼\)𝐱 = 𝟎 에서 lambda가 정해지면 \(𝐴 − 𝜆𝐼\)의 null space에 있는 non-zero vectors가 우리가 찾고자 하는 벡터

람다를 찾기 위한 방정식을 특성 방정식이라고 한다.

* \(𝐴 − 𝜆𝐼\)가 선형종속이라는 뜻은 역행렬이 없다는 뜻. 곧 ad-bc = 0 이라는 뜻이다.

![](../../.gitbook/assets/image%20%28276%29.png)



