---
description: TIL
---

# 3 Wed

## \[AI 스쿨 1기\] 9주차 DAY 3

### Big Data : SparkSQL을 이용한 데이터 분석

배움의 전형적인 패턴

* 가장 중요한 것은 버티는 힘 =&gt; 즐길줄 알기
* 막혔을 때 내가 뭘 모르는지 생각해봐야 함
* 잘하는 사람보고 기죽지 않기 =&gt; 그들이 먼저 시작했다고 생각하고 또 이것이 사실이다

![](../../.gitbook/assets/image%20%28204%29.png)

새로운 것을 처음 배울 때의 좋은 자세

* 자신이 아는 것과 모르는 것을 분명히 이해
  * 멍청한 질문은 없음
* 마음을 편하게 먹기
  * 내가 이해하기 힘들면 남들도 힘듦
  * 나보다 더 잘하는 사람은 똑똑하기 보다는 더 노력했기 때문
* 배움의 발전은 Tipping point를 거치면서 폭발하는 형태
  * 발전이 더딘 기간을 즐겨야 이러한 정체기 뒤에 폭발적인 발전의 시기가 다가온다

빅데이터에서 중요한 SQL

* 구조화된 데이터를 다룰거면 SQL은 끊임없이 중요
* 모든 대용량 데이터 웨어하우스는 SQL 기반
* Spark도 예외는 아님
  * SparkSQL
* 데이터 분야에서 일하고자 하면 반드시 익혀야할 기본 기술

관계형 데이터베이스

* 대표적인 관계형 데이터 베이스
  * MySQL, Postgres, Oracle
  * Redshift, Snowflake
* 관계형 데이터베이스는 2단계로 구성됨
  * 가장 밑단에는 테이블들이 존재. 테이블은 엑셀의 시트에 해당
  * 테이블들은 데이터베이스라는 폴더 밑으로 구성
* 테이블의 구조. 스키마라고 부르기도 한다.
  * 테이블은 레코드들로 구성
  * 레코드는 하나 이상의 필드로 구성
  * 필드는 이름과 타입으로 구성됨
* 예제 1 - 웹서비스 사용자/세션 정보
  * 사용자 ID
    * 보통 웹서비스에서는 등록된 사용자마다 유일한 ID를 부여한다
  * 세션 ID
    * 사용자가 외부 링크\(보통 광고\)를 타고 오거나 직접 방문해서 올 경우 세션을 생성
    * 즉 하나의 사용자 ID는 여러 세션 ID를 가질 수 있음
    * 보통 세션의 경우 세션을 만들어낸 소스를 채널이란 이름으로 기록
      * 마케팅 관련 기여도 분석을 위함
    * 세션 생성 시간도 기록
  * 이 정보들을 바탕으로 다양한 데이터 분석과 지표 설정이 가능
    * 마케딩 관련
    * 사용자 트래픽 관련
  * EX\)
    * 사용자 ID 100번 : 총 3개의 세션\(파란 배경\)을 갖는 예제
    * 세션 1 : 구글 키워드 광고로 시작한 세션
    * 세션 2 : 페이스북 광고를 통해 생긴 세션 =&gt; 리타게팅 광고
    * 세션 3 : 네이버 광고를 통해 생긴 세션

![](../../.gitbook/assets/image%20%28203%29.png)

SQL 소개

* SQL : Structured Query Language
* 두 종류의 언어로 구성됨
  * DDL \(Data Definition Language\) : 테이블의 구조를 정의하는 언어
  * DML \(Data Manipulation Language\) : 테이블에 레코드를 추가,삭제,갱신 할 때 사용하는 언어
* DDL
  * CREATE TABLE
  * DROP TABLE
  * ALTER TABLE
* DML
  * SELECT 필드 이름
  * FROM 테이블 이름
  * WHERE 선택조건
  * ORDER BY 정렬
  * LIMIT N \(N개만\)
  * EX
    * SELECT \* FROM raw LIMIT 10;
      * 처음 레코드 10개에 대해서 모든 필드를 리턴
    * SELECT COUNT\(1\) FROM raw
      * 이 테이블에 있는 모든 레코드의 수를 리턴
    * SELECT COUNT\(1\) FROM raw WHERE channel = 'Facebook'
      * channel이 Facebook인 모든 레코드의 수를 리턴



### Big Data : SparkSQL이란?

SparkSQL

* 구조화된 데이터 처리를 위한 Spark 모듈
* 대화형 Spark 셸이 제공됨
* 하둡 상의 데이터를 기반으로 작성된 Hive 쿼리의 경우 변경없이 최대
* 데이터 프레임을 SQL로 처리 가능

SparkSQL 사용법

* 외부 데이터베이스 기반으로 데이터 프레임 생성
* Redshift 연결
  * SparkSession을 만들 때 외부 데이터베이스에 맞는 JDBC jar를 지정
  * SparkSession의 read 함수를 호출
    * 로그인 관련 정보와 읽어오고자 하는 테이블 또는 SQL을 지정
    * 결과가 데이터 프레임으로 리턴됨
  * 앞서 리턴된 데이터프레임에 테이블 이름 지정
  * SparkSession의 sql 함수를 사용









