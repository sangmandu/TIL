# 14 Thu

## \[AI 스쿨 1기\] 6주차 DAY 4

추후 다시 정리 예정

## \[Statistics 110\] 4강- 조건부 확률 \(Conditional Probability\)

#### Present Part \[4 / 34\]

### 포함배제의 원리 추가 설명

$$ P(A_1​⋃⋯⋃A_K​)={ (n-k)! \over n!} $$

n개 중 k개의 카드에 대해서 어떤 수 m을 가진 카드가 m번째에 있을 확률은 위 식과 같다. 그런데 여기서 n개 중 k개의 카드에 대해서 적용해야 하므로​​

$$ {n \choose k} = { n! \over (n-k)!k! } $$ 

다음과 같은 식이 구해지며 이를 곱해  $$ {1 \over k!} $$만 남게 된다. 

$$ P( \bigcup_{j=1}^n A_j) = 1 - {1 \over 2!} + \cdots + (-1)^{n+1}{1 \over n!}$$

$$ P(no \  \ match) = P( \cap _{j=1}^n A_j^c) = 1-1+{1 \over 2!} - {1 \over 3!} + \cdots + (-1)^n {1 \over n!}$$  ≈ ​ ​$$ {1 \over e} $$ =&gt; 테일러 시리즈 



### Independence

#### 정의

$$ P(A∩B) = P(A)P(B)$$이 성립할 때, 사건 A와 B는 독립이다. A가 일어났다고 해서 B가 일어날 지에 대한 이야기는 하지 못한다. \(배반과의 차이점 =&gt;  배반 : A가 일어났다면 B는 일어날 수가 없다.\)

#### A, B, C의 독립

* $$P(A∩B∩C)= P(A)P(B)P(C)$$
* $$P(A∩B)=P(A)P(B), P(B \cap C) = P(B)P(C),P(B∩C)=P(B)P(C), P(C \cap A) = P(C)P(A),P(C∩A)=P(C)P(A)$$
* 전체 독립과 쌍으로 독립을 확인해야 세 사건이 독립임을 확신할 수 있다.



### Newton-Pepys Problem\(1693\)

#### 공정한 주사위를 갖고 있을 때, 다음 중 어떤 경우가 발생할 확률이 가장 높은가?

a\) 6개의 주사위 중에서 적어도 한 개가 ‘6’이 나온 경우

b\) 12개의 주사위 중에서 적어도 두 개가 ‘6’이 나온 경우

c\) 18개의 주사위 중에서 적어도 세 개가 ‘6’이 나온 경우

→ 답은 **\(a\)**

$$ P(A)=1−({5 \over 6})^6​​ \approx 0.665$$

$$ P(B) = 1 -$$\(6이 한번도 안나올 확률 + 6이 딱 한번 나올 확률\) $$ = 1−\{( {\frac {5}{6}) ^{12}} + \frac{1}{6} \times (\frac{5}{6}) ^{11} \}  \approx 0.619$$

$$P(C) = 1- {\displaystyle \sum _{k=0} ^{2}}P(C)=​​{ {18\choose k}(\frac{1}{6})^k (\frac {5}{6})^{18-k}} \approx 0.597$$

  ∴  \(a\)가 가장 발생할 확률이 높다.



### **Conditional Probability**

#### 새로운 정보를 얻었을 때, 기존의 ‘믿음/불확실성\(uncertainty\)’을 어떻게 업데이트하는가?

#### 

#### 정의

$$ P(A|B) = {\Large \frac{P(A \cap B)}{P(B)} } \\ P(A∣B)=​P(B)​​P(A∩B)​​ , (P(B) >0 P(B)>0이다) $$



#### 직관적 접근 1\) '조약돌 세계관'

![](../../.gitbook/assets/image%20%28113%29.png)



#### 직관적 접근 2\) '빈도학파\(Frequentist\) 세계관'

같은 실험을 _무한 번_  반복할 수 있다면, 

![](../../.gitbook/assets/image%20%28112%29.png)



#### 정리

1.  $$ P(A \cap B) = P(B)P(A|B) = P(A)P(B|A)$$
2.  $$ P(A_1, A_2, ... A_n) = P(A_1)P(A_2|A_1)P(A_3|A_1,A_2) ... P(A_n| A_1,..., A_{n-1})$$
3.  $$ P(A |B) = {\Large \frac {P(B|A)P(A)}{P(B)} } \\ P(A∣B)=​P(B)​​P(B∣A)P(A)$$​​  → 이를 **베이즈의 정리\(Bayes’ Theorem\)**라 한다. 







