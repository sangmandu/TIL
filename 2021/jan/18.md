---
description: TIL
---

# 18 Mon

## \[AI 스쿨 1기\] 7주차 DAY 1

### Deep Learning: 신경망의 기초 - 인공지능과 기계학습 소개

#### 인공지능

* 인간의 학습능력과 추론능력, 지각능력, 자연언어의 이해능력 등을 컴퓨터 프로그램으로 실현한 기술
* 우리가 집중할 것은 인간의 "학습 능력"

#### 일상 속 인공지능

* 음성인식 - Siri
* 추천 시스템 - eBay, Netflix
* 자율주행 - Waymo
* 실시간 객체 인식 - Face ID
* 로봇 - HUBO
* 번역 - papago



### Deep Learning: 신경망의 기초 - 기계학습 I

#### 사람\(동물\)과 기계의 학습

* 파블로프의 개 : 반복적인 신호를 제공
* 기계도 사람과 동일하지는 않지만 비슷하게 가능

#### 학습

* 경험의 결과로 나타나는, 지속적인 행동의 변화나 그 잠재력의 변화 또는 지식을 습득하는 과정

#### 기계 학습

* 어떤 프로그램이 T라는 작업을 수행한다. 이 프로그램의 성능을 P라는 척도로 평가했을 때 경험  E를 통해 성능이 개선된다면 이 프로그램은 학습을 한다고 말할 수 있다.
* 경험 E를 통해 주어진 작업 T에 대한 성능 P의 향상
* Experience, Task, Performance
* 초창기 지식기반
  * 하나의 개념에 대한 여러 특징들을 하나도 빠짐없이 나열할 수는 없다
  * 매번 새로운 모양과 다양한 특징들이 존재
    * EX\) 개는 털이 있고 혀가 길고 몸집이 가로로 길고 ...
* 데이터 중심 접근방식의 전환

#### 관찰된 데이터를 어떻게 설명할 것인가?

* 데이터의 패턴에 대한 가설
  * X = {1, 2, 3, 4}, Y = {3, 6, 9, 12}
  * suppose Y = 3X
  * Y = WX + b
* 가설의 모델은 1차원, 2차원 일수도 고차원이나 딥러닝 모델일 수도 있다

#### 기계학습의 훈련

* 임의의 매개변수 값에서 시작해서 개선하여 정량적인 최적 성능에 도달
* 주어진 문제에 대해 예측을 가장 정확하게 할 수 있는 최적의 매개변수를 찾는 작업
* 훈련을 마치면 추론을 수행 =&gt; 새로운 특징에 대응되는 목표치를 예측
* 테스트 집합에 대한 높은 성능을 일반화 능력이라고 한다.

#### 기계학습의 필수요소

* 데이터
* 데이터 규칙 존재
* 수학적으로 설명 불가능

#### 사람의 학습과 기계 학습 비교

![](../../.gitbook/assets/image%20%28141%29.png)

#### 차원의 저주

* 데이터의 차원이 높을 수록
  * 더 많은 데이터가 필요하다
  * 데이터간의 규칙을 찾기 힘들다



### Deep Learning: 신경망의 기초 - 기계학습 II

#### 과학 기술의 정립 과정

1. 데이터 수집
2. 모델 정리\(가설\)
3. 예측
4. 반복

#### 기계학습

* 데이터를 수집
* 데이터를 정리
* 모델 생성

#### 데이터의 양과 질

* 다양한 데이터를 충분한 양만큼 수집하면 과업의 성능이 향상된다.

#### 적은 양의 데이터베이스로 높은 성능을 달성하는 방법

* 데이터 희소 특성 가정 - 이상한 데이터는 존재하지 않음
* 매니폴드\(많이 끼다\) 가정 =&gt; 고차원의 데이터는 낮은 차원의 데이터들이 유사성을 지님

#### 데이터 가시화

* 4차원 이상의 초공간은 한번에 가시화 불가능

#### 선형 회귀 문제

* 직선 모델을 사용하므로 두 개의 매개변수 w와 b 필요
* 현실적으로는 선형 모델을 하기 어려움. =&gt; 잡음이 섞이기 때문 =&gt; 비선형 모델 필요
* 제곱 오차 방법으로 손실함수를 통해 개선 가능



### Deep Learning: 신경망의 기초 - 기계학습 III

#### Target distribution \(Target function\)

* 데이터를 구분짓는 구분선
* 실제로 보이지는 않으며, 데이터를 통해서 유추 가능
* input distribution과 target distribution을 통해 training exapmles를 생성
* 목적함수 error measure를 통해 learning algorithm을 수정한다.
* 이 때 가설 h를 learning algorithm을 통하여 최종 가설 g를 도출한다.

#### 과소적합과 과잉적합

![](../../.gitbook/assets/image%20%28144%29.png)

* 과소적합
  * underfitting
  * 모델의 용량\(자유도 - 파라미터 수\)이 작아 오차가 클 수 밖에 없다
  * 고차원의 모델을 사용한다.
* 과잉적합
  * overfitting
  * 훈련집합에 대해서만 완벽하게 근사화하고 새로운 데이터를 예측할 때 큰 문제 발생
  * 모델의 용량이 크기 때문에 학습 과정에서 잡음까지 수용했기 때문
  * 주로 고차원의 모델을 사용하기 때문에 오버피팅 문제가 기계학습에서 많이 발생
  * 이러한 과잉적합을 방지하기 위해 차원을 낮추는 정규화를 사용

#### 훈련집합을 여러번 수집하여 1차~12차에 반복 적용하는 실험

![](../../.gitbook/assets/image%20%28143%29.png)

* 2차
  * 매번 큰 오차 발생 =&gt; 편향이 큼
  * 모델마다 모양이 비슷함 =&gt; 낮은 변동 =&gt; 분산이 작음
* 12차
  * 매번 작은 오차 발생 =&gt; 편향이 작음
  * 모델마다 모양이 상이함 =&gt; 높은 변동 =&gt; 분산이 큼
* 기계학습의 목표
  * 낮은 편향과 낮은 분산을 가진 예측 모델을 가지는 것이 목표
  * 그러나 모델의 편향과 분산은 상충 관계이기 때문에 편향을 최소로 유지하며 분산도 최대로 낮추는 전략이 필요하다

![](../../.gitbook/assets/image%20%28142%29.png)

편향과 분산의 관계

* 용량 증가 =&gt; 편향 감소, 분산 증가 경향
* 일반화 오차 성능\(= 편향 + 분산\)은 U형의 곡선을 가짐

검증집합을 이용한 모델 선택

* 검증집합\(Validation set\)은 데이터의 양이 많을 때 사용한다.
* Original set = Training set + Testing set 의 기본 비율을 다음과 같이 바꾼다.
  * Original set = Training set + Validation set + Testing set
* Testing set을 적용하기 전에 검증집합을 이용해 미리 성능을 측정할 수 있다.

교차점증

* 교차검증\(Cross validation\)은 데이터의 양이 적을 때 사용한다.
* 데이터를 여러 부분으로 나눈 뒤 각 부분을 돌아가면서 검증집합으로 사용

부트스트랩

* 임의의 복원추출 샘플링을 반복한다
* 데이터 분포가 불균형일 때 적용한다
  * class1 : 10000개, class2 : 100개
  * class1에 대해서 치우친 학습을 할 가능성이 크다
  * class1 : 100개, class2 : 50개를 뽑아 학습하거나
  * class1 : 10000개, class2 : 10000\(복사 또는 변형으로 생성\)을 뽑아 학습한다.
  * 데이터의 양이 적으면 좋지 않기 때문에 주로 수를 늘리는 방법으로 적용한다

모델 선택의 한계와 현실적인 해결책

* 데이터의 용량보다 큰 모델을 선택한 뒤, 점점 작게 만든다. =&gt; 여러 규제 기법을 적용

규제

* 데이터 확대
  * 데이터를 더 많이 수집하면 일반화 능력이 향상됨
    * 데이터 수집은 많은 비용이 듦 =&gt; 실측자료를 사람이 일일이 표식해야 하기 때문\(labeling\)
  * 인위적으로 데이터 확대 =&gt; 재활용
    * 훈련집합에 있는 샘플을 변형한다
    * 변형 : 약간의 회전 또는 왜곡\(고유 특성은 변하지 않는 정도로\)
* 가중치 감쇠
  * 가중치를 작게 조절한다
  * 기존 함수는 훈련 집합이 변화하면 분산이 커진다.
  * 가중치를 작게 조절한 개선된 목적함수는 분산이 작다.
  * 원래 가진 모델의 용량이 다 발현되지 못하게 하는 것이 목표

지도 방식에 따른 유형

* 지도 학습
  * 특징 벡터에 대한 라벨링이 주어진 상황
  * 회귀와 분류문제로 구분
* 비지도 학습
  * 특징 벡터에 대한 라벨링이 주어지지 않음
  * 군집화 과업 \(고객 성향에 따른 맞춤 홍보 등\)
  * 밀도 추정, 특징 공간 변환 과업
* 강화 학습
  * 라벨링이 상황에 따라서 다른 상대적 목표치로 주어진다. 이를 보상이라고 한다
  * 바둑같은 게임을 할 때 적용
* 준지도 학습
  * 일부 특징 벡터는 라벨을 가지지만 나머지 벡터는 라벨이 없는 상황
  * 대부분의 데이터가 X의 수집은 쉽지만 Y는 수작업이 필요하여 최근 중요성 부각

다양한 기준에 따른 유형

* 오프라인 학습과 온라인 학습
  * 보통은 오프라인 학습을 다룸
  * 온라인 학습은 IoT 등에서 추가로 발생하는 데이터 샘플을 가지고 점증적 학습 수행
* 결정론적 학습과 확률적 학습
  * 결정론적에서는 같은 데이터를 가지고 다시 학습하면 같은 예측 모델이 만들어짐
  * 확률적 학습은 학습 과정에서 확률 분포를 사용하므로 같은 데이터로 다시 학습해도 다른 예측 모델이 만들어짐
* 분별 모델과 생성 모델
  * 분별 모델은 분류 예측에만 관심. P\(y\|x\)의 추정에 관심
  * 생성모델은 P\(x\) 또는 P\(x\|y\)를 추정함
    * 따라서 새로운 샘플을 생성할 수 있다





## \[Statistics 110\] 6강- Monty Hall 문제와 심슨의 역설 \(Monty Hall, Simpson's Paradox\)

#### Present Part \[6 / 34\]

#### **Monty Hall 문제**

![](../../.gitbook/assets/image%20%28145%29.png)

세 개의 문 중에 하나 뒤에는 자동차가 있고, 나머지 두 개 뒤에는 염소가 있다. Monty가 내가 고르지 않은 문 중 하나를 열어 염소가 있는 것을 보여줬다면, 나는 처음 고른 문에서 바꾸는 것이 유리한가, 그렇지 않은가?

i\) 수형도로 풀기 \(몬티가 2번 문을 열었다는 가정\)

![](../../.gitbook/assets/image%20%28148%29.png)

ii\) 전체 확률의 법칙으로 풀기

 $$S$$: 처음 선택에서 바꿔서 자동차 있는 문을 맞추는 사건

 $$D_j$$​​: $$j$$번 문 뒤에 자동차가 있는 사건  $$(j \in \{1, 2, 3\} )$$

 $$ P(S) = P(S|D_1)\times \large{\frac{1}{3}} + P(S|D_2) \times \large \frac{1}{3}​​ +P(S|D_3) \times \large \frac{1}{3} $$

 $$ = 0 + 1\times \large \frac {1}{3}​​ + 1 \times \large \frac {1}{3} = \frac {2}{3} $$ 

또한 Monty는 내가 고르지 않은 두 개의 문이 둘 다 염소가 있다면 두 문을 열 확률은 같으므로

 $$P(S∣ Monty가 2번문을 연다) = \large \frac{2}{3} =P(S) $$

으로, 조건부 확률과 조건부가 아닌 확률 값이 일치한다.



#### 만약 몬티홀의 문이 9999개라면?

* 대부분의 직관은 선택한 문을 바꾼다 라는 입장 =&gt; 자신의 첫 선택이 크게 가능성이 없다고 생각
* 문이 3개인 경우와 크게 다를게 없다



#### **Simpson's Paradox**\(심슨의 역설\)

부분에서 성립하는 대소 관계는 전체를 보았을 때 역전될 수도 있다. 

예시\) 심슨 가족이 사는 스프링필드에 Dr.Hibbert와 Dr.Nick, 두 명의 의사가 있교, 그들은 심장 수술과 반창고 제거 두 가지 수술을 한다고 하자. 

![](../../.gitbook/assets/image%20%28147%29.png)

의사들의 수술종류별 성공률을 보았을 때, Dr.HIbbert가 더 좋은 의사임은 분명하다.

하지만 Dr.Nick이 더 높은 전체 수술 성공률을 근거로 스스로의 경쟁력을 주장한다면, 이 또한 틀린 말은 아니다!

또 다른 예

* 야구에서 두 명의 선수가 있다. 1번 선수가 타율\(전체 타석에서 안타를 친 횟수\)이 더 높고 두 번째 시즌에서도 타율이 더 높지만 전체적으로 봤을 때 2번 선수가 타율이 더 높다.

\(수업에서 제시한 심슨 가족의 예시 외에도, [https://en.wikipedia.org/wiki/Simpson%27s\_paradox](https://en.wikipedia.org/wiki/Simpson%27s_paradox) 에서 더 많은 심슨의 역설 예시를 찾아볼 수 있다.\)

이론적 접근

A: 수술이 성공하는 사건 \(&lt;-&gt; 수술 실패\)

B: Dr. Nick가 수술을 집도하는 사건 \( &lt;-&gt; 히버트가 집도\)

C: 심장 수술을 받는 사건 \( &lt;-&gt; 반창고 제거\)

심장\)  $$P(A|B,C) < P(A|B^C,C)$$

반창고\)  $$P(A|B,C^C) < P(A|B^C,C^C)$$

로 Dr.Hibbert가 각각의 수술이라는 조건부 확률에서는 더 좋은 성적을 보일 수 있지만,

무조건부 확률은 $$P(A|B) > P(A|B^C)$$와 같이 역전될 수가 있다는 것이다. 

 $$\Large\Rightarrow$$ 여기서 C\(수술의 종류\)는 _**confounder**_ \(교란변수\)라고 하며, 이렇게 적절한 confounder에 의한 조건부 확률을 확인하지 않으면 상황에 대한 그릇된 판단을 내릴 위험이 있다.   

전체 확률의 정의를 이용해 심슨의 역설이 틀렸음을 증명할 수 있는가?

 $$P(A|B) = P(A|B,C)P(C|B) + P(A|B,C^C)P(C^C|B)$$ 에서

문제에서 주어진 조건에서 $$P(A|B,C) < P(A|B^C,C)$$,  $$P(A|B,C^C) < P(A|B^C,C^C)$$ 는 확인 가능하지만,

 $$P(C|B), P(C^C|B)$$ 가 좌항, 우항에 서로 다른 가중치로 작용하기 때문에 증명할 수 없다. 



나는 잘 이해가 안가서 이걸 참고했더니 이해가 좀 됐다.

{% embed url="https://youtu.be/NurEgMvXqvc" %}

표본 크기의 차이가 승률의 비중을 다르게 만들고 달라진 승률의 비중이 합산된 결과는 직관을 깨는 듯한 역설을 준다 라는 정리.

\(아직까지 설명을 완벽하게 할 정도로 이해는 못한 듯\)



## \[Statistics 110\] 7강- 도박꾼의 파산 문제와 확률변수 \(Gambler's Ruin and Random Variables\)

**Gambler's Ruin\(도박꾼의 파산\)**: A와 B 두 명의 도박꾼이 매 라운드 $1씩 걸고 도박을 한다. 이긴 사람은 상대방의 $1을 가져가고, 둘 중 한 명이 가지고 온 돈이 바닥날 때까지 이 과정을 반복한다. 

* 이 문제는 0부터 N까지의 수직선위에 i 지점에 있는 벌레의 무작위 행보문제와 동일하다

 p = P\(A가 한 라운드를 이길 확률\)

 q = 1-p \(B가 한 라운드를 이길 확률\)

A는 i 달러, B는  N-i 달러를 가지고 게임을 한다고 할 때, 

![](../../.gitbook/assets/image%20%28146%29.png)

p의 확률로 A가 1달러를 더 얻고, q의 확률로 1달러를 잃는다.  
0, N은 흡수상태\(absorbing state\)라 하여, 게임 종료를 나타낸다.

 $$p_i$$​​ : A가 i 달러로 시작하여 게임을 이길 확률 : $$ P(A ~wins ~game | A~ start~ at~ i~ dollars) $$

$$  p_i = p \cdot p_{i+1}+q \cdot p_{i-1}​ ( 1 \le i \le N-1)$$ 이고,  $$p_0 = 0, p_{N} = 1$$ 이다.

이를 계차방정식\(difference equation\)이라고 한다.\(미분방정식의 이산 형태\)



**guessing을 통한 풀이**

 $$p_i = x^i$$라고 하자.

 $$x^i = p \cdot x^{i+1} +q \cdot x^{i-1}$$​​ 

 $$px^2 - x +q = 0$$

 $$x = \large {\frac{-1 \pm \sqrt{1-4pq}}{2p}}$$ 이고, $$q = 1-p$$이기 때문에,  $$1-4pq = (2p-1)^2$$​​ 이 성립한다.

따라서  $$x \in \{1, \large\frac{q}{p} \}$$ 이 때, 우리가 관심있는 것은 p와 q가 다를 떄 이다.

→ 두 해가 다른 경우 다음과 같이 선형인 식으로 표현한다. 

 $$p_i = A\cdot 1^i + B \cdot (\large\frac{q}{p})^i​​   (p \ne q)$$  

여기에 조건 $$p_0 = 0,  p_{N} = 1$$ 을 대입하면, 

 $$p_0 = A+B = 0$$   $$\rightarrow B=-A$$ 

 $$p_N = A +B \large(\frac{q}{p})^N​​​  = A(1-\large(\frac{q}{p})^N)=1$$  

 $$A = \Large \frac{1}{1-(\frac{q}{p})^N}$$ 

 ****$$p_i = \Large{\frac{1-(\frac{q}{p})^i}{1-(\frac{q}{p})^{N-i}}}(p \ne q)  $$\*\*\*\*

그리고  $$p = q$$ 인 경우,

 $$x = \large\frac{q}{p}$$ 라고 놓고 $$ x \rightarrow 1$$ 의 극한을 살펴보았을 때, 

 $$\lim_{x \rightarrow 1} = \lim_{x \rightarrow 1}{\large\frac{1-x^i}{1-x^N}}​​ = \lim_{x \rightarrow 1} \large \frac{i(x^{i-1})}{N(x^{N-1})} = \large \frac{i}{N}$$ 

 $$\Rightarrow p_i = {\Large{\frac{1-(\frac{q}{p})^i}{1-(\frac{q}{p})^{N-i}}}} (p \ne q) ~  or  ~ {\large \frac {i}{N}​}~  (p = q) $$



**해석**  
[ ![](https://cphinf.pstatic.net/mooc/20180829_121/1535525545844sDFvn_PNG/7-3.PNG?type=ffn199_148)](https://www.edwith.org/harvardprobability/lecture/30899#)

하우스와 같은 돈을 가지고 시작하고, 1%정도로만 불공평한 게임이라고 해도 게임을 계속하다 보면 이길 확률이 매우 적어지게 된다. \('도박꾼의 파산'\)

**확인할 점**: 게임이 끝나지 않고 영원히 계속될 확률이 있는가?

게임이 공평한 상황에서 \(p = q\) B가 \(N-i 달러를 갖고\) 이길 확률은  $$\large \frac {N-i}{N}​$$이다.

 $$\large \frac{i}{N} + \frac{N-i}{N}=1 $$이므로 게임이 계속될 확률은 0이다.



**확률변수\(Random Variable\)**: 표본공간 S부터 실수 체계 R로 '맵핑' 하는 함수

[![](https://cphinf.pstatic.net/mooc/20180829_53/1535526243836RIiXb_PNG/7-4.png?type=w760)](https://www.edwith.org/harvardprobability/lecture/30899#)

**예시\) 베르누이\(Bernoulli\) 확률변수**

X가 0\(실패\), 1\(성공\) 두 가지의 값만 가질 수 있으며,

P\(x=1\)=p, P\(X=0\) = 1-p 일 때

X는 Bernoulli\(p\) 분포를 따른다고 한다.

**예시\) 이항\(Binomial\) 확률변수**

n번의 독립적인 베르누이\(p\) 시행에서 성공 횟수의 분포는 Bin\(n,p\) 를 따른다고 한다.

* 이항확률변수의 확률질량변수\(PMF\): $$P(X = k) = {n\choose k} p^k(1-p)^{n-k} $$
* 이항확률변수의 특징

 X~Bin\(n,p\),  Y~ Bin\(m,p\) 일 때, 

 X+Y~Bin\(n+m,p\) 를 따른다.

## \[Statistics 110\] 8강- 확률변수와 확률분포 \(Random Variables and Their Distributions\)

\*\*\*\*



