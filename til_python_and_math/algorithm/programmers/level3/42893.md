---
description: '210728'
---

# 매칭 점수

```python
'''
https://programmers.co.kr/learn/courses/30/lessons/42893
매칭 점수
[풀이]
1. 각 페이지마다 기본점수와 링크점수를 기록하기 위해 dictionary 선언
=> 이 때 각 value는 [기본점수, 링크점수] 꼴로 저장될 것이다
2. 대소문자 구별을 하지 않으므로 word와 page를 lower()
=> url은 늘 소문자이므로 예외 처리 하지 않아도 됨(대문자 url이 등장하지 않는다는 전제가 있는 듯 하다)
3. 각 페이지의 링크를 index로 기억하기 위해 links 리스트 선언
4. pages 반복문 시작
=> re.search로 페이지 주소 찾기. 이 때 이 주소를 links에 저장해서 index로 매칭
=> re.finditer로 조건에 알맞게 word와 매칭
5. pages 반복문 다시 시작
=> re.finall로 외부링크 찾기.
=> 왜 반복문을 다시 시작? 해당 외부 링크가 실제로 존재하는 페이지인지 알려면 검사를 한번 끝내야 하기 때문.
6. 기본점수와 링크점수의 최대값에 해당하는 인덱스 반환
=> index는 동일한 값이 있어도 가장 앞에 있는 인덱스 반환
7. 테스트 케이스 오류는 소스코드 아래 참조할 것.
'''
import re
from collections import defaultdict

def solution(word, pages):
    site = defaultdict(list)
    word = word.lower()
    links = []

    for page in pages:
        page = page.lower()
        link = re.search('<meta property="og:url" content=".+"', page).group()
        link = link[link.find("http"):-1]
        links.append(link)

        match = 0
        for words in re.finditer(word, page):
            if not (page[words.start()-1].isalpha() + page[words.end()].isalpha()):
                match += 1

        site[link].extend([match, 0])

    for idx, page in enumerate(pages):
        export = re.findall('<a href="\S+"', page)
        for e in export:
            key = e[9:-1]
            if key in site.keys():
                site[key][1] += site[links[idx]][0] / len(export)

    lst = [a + b for a, b in site.values()]
    return lst.index(max(lst))
'''
1. [9번]
=> content="https://careers.kakao.com/index" 로만 찾으면 틀리게 된다.
무조건 <meta property="og:url" content="https://careers.kakao.com/index" 형식으로 찾아야 한다.
아마도, 메타 태그가 없는 컨텐츠=주소 형식이 존재하는 것 같다. 9번 케이스에서 2개 이상의 주소가 찾아진다.
2. [4, 6, 8, 10, 17번]
=> 일단, <a 없으면 오류난다. 만약 있는데도 오류나면 바로 아래 참조.
=> 이거 진짜 골칫거리다. 나는 초기에 re.findall('<a href=".+"', page)로 찾았었는데,
아무리 해도 반례를 찾을 수 없었다. 진짜 이거에 몇시간 쓴 듯.
사람들은 <a href="" 외에도 <a href="" test="" 꼴이 있다느니 하는 이야기가 많았는데,
아니 문제에 턱하니 다른 attribute가 없다고 명시되어 있는데 진짜로 테케가 잘못됐다고??
결론은, 테케는 문제가 없다, url에 문제가 있다...
re.findall('<a href="\S+"', page) 로 찾으면 된다.
이게 무슨뜻이냐면, \S는 공백이 아닌 문자(스페이스바, 엔터, 탭 제외)를 의미하는데 주소에 공백이 있다는 것이다.
비정상적인 url이 들어있는 것 같다. 근데 웃긴건 공백문자(스페이스바, 엔터, 탭)을 split으로 제거하고 실행해보면 오류.
나도 왜 여기서 . 대신 \S를 사용해야 하는지 명확히 설명할 수가 없다. 문제 테스트케이스가 정말 궁금해진다. 
3. [그 외]
=> '링크점수는 해당 웹페이지로 링크가 걸린 다른 웹페이지의 기본점수 ÷ 외부 링크 수의 총합이다.' 를 잘못 구현
=> 또는, '검색어가 "aba" 일 때, "abab abababa"는 단어 단위로 일치하는게 없으니, 기본 점수는 0점이 된다.'
이게 은근 쉽지 않다. @ababa@, @abaaba@, abaaba 같은 경우에서 모두 찾을 수 없어야 하며
@aba@aba@,aba@aba@, @aba@aba 같은 경우에서 모두 찾아야 한다.
'''
```

