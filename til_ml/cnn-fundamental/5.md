---
description: '210727'
---

# CNN 모델 구현 및 성능 향상 기본 기법 적용하기

## CIFAR10 데이터세트를 이용하여 CNN 모델 구현 실습 - 01

이미지넷보다 크기가 작아서 학습하는데 오래걸림. 이미지넷은 백만개 정도의 이미지. 그래서 좀 더 크기가 작은 CIFAR 사용. 6만개의 데이터가 있음.

* 이 중 훈련 데이터는 5만개, 테스트 데이터는 1만개

```python
def show_images(images, labels, ncols=8):
    figure, axs = plt.subplots(figsize=(22, 6), nrows=1, ncols=ncols)
    for i in range(ncols):
        axs[i].imshow(images[i])
        label = labels[i].squeeze()
        axs[i].set_title(NAMES[int(label)])
```

데이터를 이미지로 보여주는 함수.

* figure는 전체 액자를 의미하며 axs는 개별 이미지\(축\)를 의미한다.
* figsize는 액자의 크기.
* nrows는 가로줄 개수
* ncols는 세로줄 개수

라벨 같은 경우는 초기에 \(50000, 1\)과 \(10000, 1\)의 2차원 형태로 존재하므로 1차원으로 스퀴즈 해주는 모습



#### 이미지 전처리

이미지의 각 픽셀값을 255.0 으로 나누어서 0~1사이의 값으로 존재하게 함.

추후에, `sparse categorical crossentropy` 를 알아보기 위해 원-핫 인코딩을 적용하지 않았음



#### CNN 2D

Convolution과 ReLU를 2번 하기 때문에 2D이다. 3번 하면 3D. 이 때 입력 채널은 항상 4차원이어야 한다. \(이미지 개수, 세로, 가로, 채널\)

* 3차원이어도 작동은 하지만, 꼭 4차원으로 입력할 것을 기억하자





## CIFAR10 데이터세트를 이용하여 CNN 모델 구현 실습 - 02

```python
x = Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu')(x)

x = Conv2D(filters=64, kernel_size=(3, 3), padding='same')(x)
x = Activation('relu')(x)
```

* Conv2D에서 활성화를 함께 할 수도 있고 3-4번 라인처럼 따로할 수도 있다.





## CIFAR10 데이터세트를 이용하여 CNN 모델 구현 실습 - 03









## 가중치 초기화\(Weight Initialization\)의 이해와 적용 - 01









## 가중치 초기화\(Weight Initialization\)의 이해와 적용 - 02









## 배치 정규화\(Batch Normalization\) 이해와 적용 - 01









## 배치 정규화\(Batch Normalization\) 이해와 적용 - 02

## 학습 데이터 Shuffle 적용 유무에 따른 모델 성능 비교

## 배치크기 변경에 따른 모델 성능 비교

## 학습율\(Learning Rate\) 동적 변경에 따른 모델 성능 비교

## 필터수와 층\(Layer\) 깊이 변경에 따른 모델 성능 비교

## Global Average Pooling의 이해와 적용

## 가중치 규제\(Weight Regularization\)의 이해와 적용

