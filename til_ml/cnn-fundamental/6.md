---
description: '210728'
---

# 데이터 증강의 이해 - Keras ImageDataGenerator 활용

## 데이터 증강\(Data Augmentation\)의 이해

#### 데이터 증강 개요

CNN 모델의 성능을 높이고 오버피팅을 극복할 수 있는 가장 좋은 방법

* **다양한** 유형의 학습 이미지 데이터의 **양** 을 늘리는 것임
* 이미지 데이터는 데이터 양을 늘리기 쉽지 않음

Data Augmentation은 학습 시에 원본 이미지에 다양한 변형을 가해서 학습 이미지 데이터를 늘리는 것과 유사한 효과를 발휘하고자 하는 것

원본 학습 이미지의 개수를 늘리는 것이 아니라, 학습 시 마다 개별 원본 이미지를 변형해서 학습을 수행하는 것

* 6만개의 이미지를 10번의 변형을 통해 60만개의 이미지를 생성하는 것이 아니다
* 6만개의 이미지를 10번의 변형을 거쳐 각 Iteration 마다 다르게 입력하는 것

#### Augmentation 유형

공간 레벨 변형

* Flip : 대칭 변환\(상하좌우\)
* Crop : 특정 영역 확대
* Affine : 회전, 수평이동, 크기변환, 압축

픽셀 레벨 변형

* 밝기 변환, 채도 변환, 명도 변환, 그레이 스케일, 혼합 등



대표적으로 `Keras ImageDataGenerator` 가 Augmentation을 지원한다.

* 장점
  * 매우 쉽게 Aug. 가능
* 단점 
  * 제한적인 변환 기능
  * 속도가 느림
  * 임의로 적용되기 때문에 각 기능별로 변환 확률을 정할 수 없음
* 그 외에도 다음과 같은 것들이 있다.
*  `Albumentations` , `ImgAug`
  * 다양한 Aug. 기법 제공 및 적용 확률 제공
  * Object Detection이나 Segmentation도 같이 변환
  * 케라스 파이프라인 통합을 위한 별도의 작업이 필요하다
* `Tensorflow Image Libarary`
  * 다양한 Image API 기능 제공. OpenCV나 scikit-image같은 기능을 많이 제공하려고 함
  * 빠른 Aug. 속도
  * tf.dataset과 쉽게 통합되고 Keras Layer와 결합되면 GPU 사용 가능
  * 다양한 Aug 기능이 없고, 입력 데이터 타입이 Numpy가 아니라 Tensor 여야 되서 불편함이 있음



## Keras의 ImageDataGenerator 특징

#### ImageDataGenerator 특징

* Keras 내에서 쉽게 Aug. 가능
* 그렇지만 Aug. 기능이 제한적이다. 그러나 기본적인 기능만으로도 효율적이게 적용 가능
* 개별적으로 이미지 변환을 적용하기가 어렵고 시간도 상대적으로 오래 걸린다.
* Preprocessing과 fit\(\)이 밀접하게 연결하여 적용된다.

#### 메커니즘

1. 이미지 파일
2. ImageDataGenerator
   * 다양한 Aug. 설정
   * rescale 설정
   * 기타 Preprocessing 설정
3. Iterator
   * Batch 크기 만큼 데이터 할당
4. Model
   * Iterator 옵션 설정

Aug 유형 중 ZCAWhitening은 버그로 인해 사용에 유의해야 한다

* 보통 사용 지양





## ImageDataGenerator로 Augmentation 적용 - 01

```python
from tensorflow.keras.preprocessing.image import ImageDataGenerator

data_generator = ImageDataGenerator(horizontal_flip=True)

image_batch = np.expand_dims(image, axis=0)
print('image_batch shape:', image_batch.shape)

data_generator.fit(image_batch)
data_gen_iter = data_generator.flow(image_batch)

aug_image_batch = next(data_gen_iter)

aug_image = np.squeeze(aug_image_batch)
print('aug_image shape:', aug_image.shape)

aug_image = aug_image.astype('int')
show_image(aug_image)
```

* 3 : Horizontal Flip\(좌우 반전\)을 적용. horizontal\_flip=True을 적용했지만 반드시 변환하는 것은 아님. Random하게 원본 데이터를 유지하거나 변환 결정. 따라서 실제 실행해보면 반전이 된 이미지가 출력될수도, 원본 이미지가 출력될 수도 있다.
* 5 : ImageDataGenerator는 여러개의 image를 입력으로 받음. 따라서 3차원이 아니라 batch를 포함한 4차원 array를 입력받음. np.expand\_dims\(\)로 차원 증가.
* 8 : ImageDataGenerator 적용. fit\(\)후 flow\(\)로 image batch를 넣어주어야 함. fit\(\)은 이후에 batch normalization을 하기위해 필요한 과정이고 필수적인 파이프라인 요소는 아니다. 또, flow\(\)는 파이프라인을 구성하는 단계이지 실제로 실행하는 것이 아니다. 실행은 다음 코드
* 11 : ImageDataGenerator를 동작하기 위해서는 next\(\)등으로 iteration을 호출해야한다
* 13 : 반환된 데이터는 batch까지 포함된 4차원 array이므로 다시 3차원 image array로 변환.
* 16 : 반환된 pixel값은 float임. 이를 다시 int형으로 변경 후, 이미지 시각화



```python
# 빈공간을 가장 가까운 곳의 픽셀값으로 채움. 
data_generator = ImageDataGenerator(width_shift_range=0.4, fill_mode='nearest')
show_aug_image_batch(image, data_generator, n_images=4)

# 빈공간 만큼의 영역을 근처 공간으로 채움. 
data_generator = ImageDataGenerator(width_shift_range=0.4, fill_mode='reflect')
show_aug_image_batch(image, data_generator, n_images=4)

# 빈공간을 이동으로 잘려나간 이미지로 채움
data_generator = ImageDataGenerator(width_shift_range=0.4, fill_mode='wrap')
show_aug_image_batch(image, data_generator, n_images=4)

# 특정 픽셀값으로 채움. 이때 특정 픽셀값은 cval 값으로 채움
data_generator = ImageDataGenerator(width_shift_range=0.4, fill_mode='constant', cval=0)
show_aug_image_batch(image, data_generator, n_images=4)
```

* shift Aug. 를 적용할 때는 4가지 fill\_mode가 있다. 기본적으로 nearest 로 설정되어 있다.
  * nearest : 가장 가까운 곳의 픽셀값으로 채우기
  * reflect : 잘린 만큼 대칭해서 채우기
  * wrap : 잘린 만큼 반대쪽에서 채우기
  * constant : 잘린 만큼 특정 픽셀값\(cval\)으로 채우기
* 다음 결과를 보면 이해가 쉽다

![](../../.gitbook/assets/image%20%28720%29.png)

## ImageDataGenerator로 Augmentation 적용 - 02

shift 뿐만 아니라, rotation 역시 fill\_mode로 채워진다. \(default는 nearest\) 왜냐하면, 90도, 180도가 아닌이상 45, 60도의 회전에서는 빈공간이 생기기 때문이다. Zoom\(=Scale\) 도 마찬가지!



Scale과 Crop의 차이?

* Scale은 비율을 유지하면서 확대하고
* Crop은 특정 영역을 자른다음에 원본 크기로 리사이즈 하는 것



Shear

일정 각도로 이미지를 늘이기

![](../../.gitbook/assets/image%20%28722%29.png)



Brightness\_range

* 부동 소수점값이 입력 된다. 범위로 입력해야 한다.
* 0에 가까울수록 원본 이미지보다 어둡고 1보다 커질수록 원본 이미지보다 밝다



Channel Shift

* 기존 픽셀값의 평균값을 변환한다

![](../../.gitbook/assets/image%20%28725%29.png)



ZCA Whitening

* 백색 노이즈와 관련된 변환



Normalization

* featurewise\_center = True이면 RGB 각 픽셀값에서 개별 채널들의 평균 픽셀값을 빼서 평균이 0이 되게 한다
* featurewise\_std\_normalization = True 이면 RGB 각 픽셀값에서 개별 채널들의 표준 편차값으로 나눈다
* rescale = 255.0 으로 하면 0~1 사이의 값이 되도록 모든 픽셀값은 255로 나눈다
* 이 때 rescale과 featurewise옵션은 같이 안쓰는 것이 좋다.



## CIFAR10 데이터 셋에 Augmentation 적용 후 모델 성능 비교 - 01

```python
from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_generator = ImageDataGenerator(
    #rotation_range=20,
    #zoom_range=(0.7, 0.9),
    horizontal_flip=True,
    #vertical_flip=True,
    rescale=1/255.0
)
valid_generator = ImageDataGenerator(rescale=1/255.0)

flow_tr_gen = train_generator.flow(tr_images, tr_oh_labels, batch_size=BATCH_SIZE, shuffle=True)
flow_val_gen = valid_generator.flow(val_images, val_oh_labels, batch_size=BATCH_SIZE, shuffle=False)
```

* 기존에 `model.fit` 에서 하던 작업들을 `generator.flow` 에서 하게 된다.
  * val 데이터와 test 데이터는 셔플이나 Aug.를 할 필요가 없다.

```python
'''
history = model.fit(x=tr_images, y=tr_oh_labels, batch_size=32, epochs=30, shuffle=True,
                    validation_data=(val_images, val_oh_labels),  
                    callbacks=[rlr_cb, ely_cb] )
'''
# steps 횟수를 구하기 위해 학습 데이터의 건수와 검증 데이터의 건수를 구함. steps = ceil(학습 데이터 건수/BATCH_SIZE)
tr_data_len = tr_images.shape[0]
val_data_len = val_images.shape[0]
history = model.fit(flow_tr_gen, epochs=40, 
                    steps_per_epoch=int(np.ceil(tr_data_len/BATCH_SIZE)),
                    validation_data=flow_val_gen, 
                    validation_steps=int(np.ceil(val_data_len/BATCH_SIZE)),
                    callbacks=[rlr_cb, ely_cb])
```

* 전에는 주석과 같이 인자를 할당했었음. 제너레이터를 사용후에는 모델의 인자로 바로 제너레이터를 할당
  * 기존에는 `x =`  형태로 입력되었다.
  * 지금도 `x` 에 할당된 것이 맞고 shift + tab을 눌러보면 x에는 여러 타입의 인자가 들어올 수 있다는 것을 알 수 있다
* `steps_per_epoch` : 필수적인 요소는 아니다. 쓰지 않더라도 알아서 계산. data length // batch\_size 만큼
  * `validation_steps` 도 마찬가지



## CIFAR10 데이터 셋에 Augmentation 적용 후 모델 성능 비교 - 02

Augmentation을 적용하니 train 데이터의 accuracy와 valid 데이터의 acc, 그리고 test 데이터의 acc간격이 작아졌다.

그러나, 원본 이미지 상황에 맞지 않거나 과도한 Aug.은 오히려 성능을 저하시킴

* 왜냐하면 Zoom 같은 경우는 확대 및 축소를 하면 object의 특징을 잃을 수 있다.
  * 예를 들면, 가운데에 위치한 자동차의 경우 확대를 했을 때 자동차의 창문 같은 것들이 없어질 수 있다.
  * 또한, 확대를 할 경우 이미지의 선명도가 떨어진다.
* 또 시간이 더 걸리게 된다.
  * Aug. 를 적용하면 CPU와 GPU의 동기화가 잘 이루어지지않는다.
  * 단순히 Aug가 오래걸려서 그런것이 아님

