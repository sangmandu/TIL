---
description: '210820'
---

# \(09강\) Hyperparameter Tuning

학습을 할 때 사람이 지정해야 하는 파라미터를 하이퍼 파라미터라고 부른다. 이러한 하이퍼 파라미터를 잘 조정해서 성능을 높이는 방법을 다루게 된다.

성능을 높이는 방법

* 모델을 수정
* 데이터를 추가 또는 변형
* 하이퍼 파라미터 튜닝

일반적으로, 데이터가 가장 성능을 높일 수 있는 소스이다. 1번이 가장 중요하지만 좋은 모델은 이미 일반화되있기 때문이다.

### Hyperparameter Tuning

사람이 지정하는, 모델이 학습하지 않는 값

* 학습률, 모델의 크기, 옵티마이저

하이퍼 파라미터에 의해 값이 크게 좌우되는 경우가 많지는 않다. 왜? 데이터가 워낙 많아졌으니까! 정말로, 최종 단계에서 성능을 높이기 위해서 도전한다

![](../../../../.gitbook/assets/image%20%28944%29.png)

배치사이즈도 하이퍼 파라미터.



가장 기본적인 방법은 `Grid search` 이다. 하이퍼 파라미터를 찾을 때 일정 범위 안에서 하나씩 골라서 성능을 비교하는 방법이다. `Random search` 는 범위를 정하지 않고 임의로 정하는 방법이다.

![](../../../../.gitbook/assets/image%20%28941%29.png)

보통은 `Random search` 로 성능이 향상하는 지점을 대략적으로 찾고 `Grid search` 로 세세한 부분을 찾는다.

그러나, 지금은 2018년에 발표된 Baesyan Optimizer Hyperparameter Tuning, BOHT 이후로 이 방법을 쓰기 때문에 잘 쓰지 않는 방법이 되었다.



### Ray

Multi node Multi Processing을 지원하는 모듈이다. ML/DL의 병렬 처리를 위해 개발되었다. 현재는 분산병렬의 표준모듈이며 하이퍼 파라미터를 찾기위한 다양한 기능을 제공한다.







