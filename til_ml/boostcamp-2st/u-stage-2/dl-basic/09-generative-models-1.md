---
description: '210813'
---

# \(09강\) Generative Models 1

## Introduction

Generative model을 만든다, 학습한다라는 것은?

* 그럴듯한 이미지나 문장을 만드는 것이라고 보통 생각한다
* 그러나, 단순히 "생성"의 의미만을 가지는 것이 gen model의 전부는 아니다. 그것보다 더 많은 개념을 포함한다

![](../../../../.gitbook/assets/image%20%28903%29.png)

* Generation : 학습 데이터셋에 없는 강아지 사진을 만드는 것도 gen이 할수있는 일. 
* Density estimation : 강아지 같은지 아닌지 구별할 수 있는 능력
  * 마치 분류모델과 같다.

어떤 모델이 Generative model이라고 하면, 그 모델은 단순히 generation 하는 능력뿐만 아니라 분류할 수 있는 능력까지 포함한다.

* explicit model에 속한다. 입력이 주어졌을 때 입력에 대한 확률값을 얻어낼 수 있는 모델을 뜻한다.
* feature learning : gen model은 unsupervised learning도 가능하다고 이야기 한다.



## Basic Discrete Distributions

예를 한번 들어보자

![](../../../../.gitbook/assets/image%20%28910%29.png)

한 픽셀당 표현할 수 있는 색은 몇가지일까?

* 256 \* 256 \* 256

그렇다면 색을 정의하기 위해 필요한 파라미터 수는 몇개일까?



![](../../../../.gitbook/assets/image%20%28902%29.png)

바이너리 이미지\(흑백 이미지\)에서 픽셀이 n개라면 만들 수 있는 이미지의 경우의 수는 몇개일까?

* $$ 2^n $$

그렇다면 차원이 n인 벡터 X가 n개 있다고 했을 때, 이 벡터를 정의하려면 필요한 파라미터 수는 몇개일까?

* $$ 2^n -1$$

여기서, 요지는 n개의 픽셀을 구성할 때 조금 더 적은 파라미터를 사용할 수 없을까? 라는 것. 그래서 다음과 같은 가정을 둔다. 픽셀들은 서로 "Independent" 하다.

* 현재 픽셀이 주변 픽셀에게 영향을 주지 않고, 영향을 받지않는다는 뜻으로 해석하면 된다.

그렇게 되면 경우의 수는 똑같지만 필요한 파라미터 수는 n개만 있으면 된다.

* 각각의 픽셀은 베르누이 분포를 따르므로 필요한 모수는 확률 p 하나이다. 또 확률 p\(x1, ... xn\)에서 각각의 x는 독립이므로 joint distribution이 가능해서 각각의 확률곱 p\(x1\)p\(x2\)...p\(xn\) 으로 표현이 가능하다. 따라서 필요한 파라미터의 개수는 n이다.
* 그러나 이건 어디까지나 Independent Assumption이 작용했을 때의 이야기

Fully Dependent하면 파라미터수가 너무 많고, Independent 하자니 파라미터수는 줄어들어서 좋지만 표현할 수 있는 이미지가 적어지기 때문에 그 중간쯤을 찾는 것이 목표

그래서 Conditional Independence 를 사용하게된다.

## Conditional Independence

![](../../../../.gitbook/assets/image%20%28899%29.png)

기본적으로 쓰는 연쇄법칙이다. x의 독립/종속에 관계에서 항상 만족한다

![](../../../../.gitbook/assets/image%20%28911%29.png)

마찬가지로 항상 만족하는 법칙

![](../../../../.gitbook/assets/image%20%28900%29.png)

이는 항상 만족하지는 않다. z가 주어졌을 때 x와 y가 independent 하다면 만족한다.



체인룰을 사용할 때 필요한 파라미터 개수는 몇개일까?

![](../../../../.gitbook/assets/image%20%28897%29.png)

![](../../../../.gitbook/assets/image%20%28904%29.png)

난 이부분이 이해가 잘 안갔다가 질문하고 고민하고 한 끝에 이해했다

> 종속적:  
> p\(x2\|x1\)은 다음과 같이 두가지로 표현 가능  
> p\(x2\|x1=1\)과 p\(x2\|x1=0\)
>
> * p\(x2\|x1=1\) 에서 필요한 x2를 결정하는확률 q1
> * p\(x2\|x1=0\) 에서 필요한 x2를 결정하는 확률 q2
>
> 이 때 확률 q1과 q2가 필요하므로 종속적일 때는 세 개\(p, q1, q2\)의 파라미터 필요\(2^n-1개\)
>
> * 만약 q1 = q2가 같다면 x1이 뭐든간에 x2의 확률이 같다는 것이므르 종속이라는 가정에 위배
>
> 독립적:  
> p\(x2\|x1\) = p\(x2\) 이므로 x2를 결정하는 확률 q 따라서, 독립적일 때는 두 개\(p, q\)의 파라미터 필요\(n개\)



이제 Markov assumption이라고 가정해보자. 그럼 확률은 다음과 같다.

* 이는 현재 데이터는 가장 최근에 데이터 하나에만 의존적이라는 것\(=영향을 받는다\)

![](../../../../.gitbook/assets/image%20%28908%29.png)

필요한 파라미터 수는 다음과 같다

![](../../../../.gitbook/assets/image%20%28901%29.png)

* x1은 한개가 필요하고 그 뒤부터는 2개씩 필요하므로



잘보면 처음에 Fuuly Independent 할 때는 $$ 2^n $$개이고 Markov assumption을 적용하니 지수가 한 차원 내려간 $$ 2n-1 $$그리고 완전 독립일 때는 $$ n $$개이다.

따라서 우리가 조건을 어떻게 정해주냐에 따라서 필요한 파라미터 수가 달라지며 독립에 가까울 수록 적어지고 종속에 가까울 수록 많아진다.

이렇게 conditional independency를 잘 활용하는 모델을 Auto-regressive Model 이라고 한다.



## Auto-regressive Model

![](../../../../.gitbook/assets/image%20%28909%29.png)

위와 같이 MNIST 28\*28 바이너리 이미지가 있다고 하자. 우리의 목표는 p\(xi\)를 학습하는 것.\(i는 1부터 784\) 이 때 p\(x\)를 어떻게 정의할까?

바로, 연쇄법칙을 사용해서 결합 분포로 변경하는 것. 이 때 여러 조건을 설정할 수 있는데, 현재 데이터가 바로 전 데이터에만 영향을 받든, 현재 데이터가 첫 데이더부터 바로 전 데이터까지에 영향을 받든 모두 Auto-regressive Model이라고 할 수 있다.

숫자든, 문자든, 이미지든 순서를 정해주는 것이 중요하다.

* 이미지의 순서를 정해주는 것은 애매하다. 가로로 한줄로 나열할 수도 있고, 지그재그로 순서를 정할 수도 있다. 이에 따라 성능도 달라질 것이고 방법론도 달라질 것이다.

Auto-reg가 데이터 1개만을 고려할 때 AR-1 모델이라고 하며 n개를 고려할 때는 AR-n 모델이라고 한다

### NADE: Neural Autoregressive Density Estimator

![](../../../../.gitbook/assets/image%20%28907%29.png)

각 데이터셋의 순서의 신경망은 이전 데이터셋을 입력받으므로 명확히 Autoreg 모델이다. 각 신경망은 점점 입력 데이터의 차원이 커지게되고 이에 따라 가중치의 크기도 커지게 된다.

이 모델의 확률분포는 다음과 같이 구할 수 있다.

![](../../../../.gitbook/assets/image%20%28906%29.png)

impulse 모델은 generating만 할 수있는데 반해 explicit 모델을 generate와 classify를 둘 다 할 수 있다.

또, 만약에 연속확률분포일경우 가우시안 혼합모델를 사용할 수 있다.

### Pixel RNN

RNN을 사용해서 픽셀을 생성하는 모델

![](../../../../.gitbook/assets/image%20%28905%29.png)

autoreg 모델은 FC를 거쳐서 만들어지는데, pixel rnn은 recurrent를 통해 generation이 이루어진다.

또, 이 때 ordering 하는 방법에 따라 두 가지 방법이 생기는데

![](../../../../.gitbook/assets/image%20%28898%29.png)

Row LSTM은 자신보다 위쪽에 있는 정보를 활용하겠다는 것이고 Diagonal BiLSTM은 자신보다 이전에 있는 정보를 활용하겠다는 것이다



