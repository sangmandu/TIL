---
description: '210825'
---

# \(6강\) Model 2

### Pretrained Model

ImageNet은 2만개의 카테고리와 1400만장의 높은 품질의 데이터셋이다. 이러한 ImageNet이 등장하면서 이 데이터셋을 통해서 모델의 검증이 이루어지게 되었고 컴퓨터 비전의 발전이 급격히 시작되었다.

![](../../../.gitbook/assets/image%20%28999%29.png)

Augmentation 만으로는 모델의 일반화에 한계가 있다. 또한, 매번 대량의 데이터셋을 구하기도 어렵고 매번 학습하기도 어렵다. 이런 비효율성을 해소하기 위해 대용량의 데이터셋을 학습한 모델을 활용한다. 좋은 품질과 대용량의 데이터로 미리 학습한 모델을 바탕으로 내 목적에 맞게 다듬어서 사용하는 것. 이렇게되면 시간적으로 매우 효율적이게된다.

`torchvision` 에는 여러 모델을 모아두었으며, 여기서 모델을 가져올 수 있다. 또한 `pretained=True` 를 입력해주면 학습된 파라미터까지 같이 가져올 수 있다.

![](../../../.gitbook/assets/image%20%281009%29.png)

`또, timm` 에도 여러 모델들이 있다. `torchvision` 과 차이점은 좀 더 실험적으로 만든 여러 가지의 모델이 존재한다는 것. 예를 들자면, 단순히 `efficientnet` 하나만 있는것이 아니라 이 모델에 대한 여러 서브모델이 존재한다. 아래 예시는 Vision Transformer 모델에 대해서 여러 모델을 가지고 있는 모습

![](../../../.gitbook/assets/image%20%281003%29.png)



이미지넷을 학습한 모델은 다음과 같은 구조를 가진다고 하자.

![](../../../.gitbook/assets/image%20%281011%29.png)

이 모델은, 실생활에 존재하는 이미지를 1000개의 다른 Class로 구분한 모델이다.

> 여기서 중요한 점이 무엇이냐면, 단순히 이미지 분류 모델이고 성능이 좋다고 해서 가져다가 쓰면 안된다는 것이다. 해당 모델이 내가 해결하고자 하는 문제에 적용될 수 있는지를 꼭 확인해야한다.

![](../../../.gitbook/assets/image%20%281007%29.png)

과연, 구름을 분류하려는 문제에서 이미지넷 모델을 가져다 쓰면 성능이 나올까 고민해보자. 기존에 이미지넷 데이터셋에 구름이 있을지 없을지 확인해봐야 한다. 구름이 없다면 pretrained 모델을 불러도 성능이 안나올 수도 있다. 또, 구름이 있다 하더라도 구름의 종류까지는 구별하지 않았을 것이므로 이 부분에 대해서 성능을 장담할 수 없다.



![](../../../.gitbook/assets/image%20%281006%29.png)

학습 데이터가 충분할 때는, 유사성이 낮더라도 충분히 Backbon을 업데이트 할 수 있으므로 위처럼 학습이 가능하다.

CNN Backbon은 freezing 한 채로 Classifier만 바꾸는 것을 Feature Extraction 이라고 하며 모두 바꾸는 것을 Pine Tuning이라고 한다.

Low Similiarity 의 관계에 있더라도 pretrained된 모델을 사용하는 것이 되지 않은 모델을 사용하는 것 보다 실험적으로 성능이 좋다고 한다.



![](../../../.gitbook/assets/image%20%281010%29.png)

그러나,  데이터가 부족할 때는 backbone을 업데이트 하기가 어렵다. 만약에 유사도가 높다면 분류기만 학습해서 사용하게 되고 유사도가 낮다면 오버피팅이나 언더피팅으로 성능이 안나올 가능성이 높기 때문에 사용을 추천하지 않는다.



