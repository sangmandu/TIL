---
description: '210805'
---

# \(AI Math 5강\) 딥러닝 학습방법 이해하기

### 소프트맥스

모델의 출력을 확률로 해석할 수 있게 변환해 주는 연산이다. 분류 문제를 풀 때 선형모델과 소프트맥스 함수를 결합하여 예측한다.

추론을 할 때는 원-핫 벡터로 최댓값을 가진 주소만 1로 출력하는 연산을 사용해서 softmax를 사용하지는 않는다.



### 신경망

선형모델과 활섬함수를 합성한 함수이다.

다층 퍼셉트론, MLP는 신경망이 여러층으로 합성된 함수이다.



### 활성함수

실수공간에서 정의된 비선형 함수로서 딥러닝에서 매우 중요한 개념이다.

* 활성함수를 사용하지 않으면 딥러닝의 힘을 잃는다.

시그모이드나 tanh 함수는 전통적으로 많이 쓰이던 함수지만 최근에는 ReLU 함수를 많이 사용한다.



### 층을 여러개 쌓는 이유

층이 깊을 수록 목적함수를 근사하는데 필요한 노드의 숫자가 훨씬 빨리 줄어들어서 좀 더 효율적으로 학습이 가능하다.

* 층이 얇으면 필요한 뉴런의 숫자가 기하급수적으로 늘어난다. 그래서 넓은 신경망이 된다.
* 층이 깊어질수록 딥러닝 모델이 학습하기는 어려워질 수 있다.

