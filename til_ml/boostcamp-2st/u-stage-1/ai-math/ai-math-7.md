---
description: '210805'
---

# \(AI Math 7강\) 통계학 맛보기

### 모수란?

통계적 모델링이란, 적절한 가정 위에서 확률분포를 추정하는 것이 목표이며 기계학습과 통계학이 공통적으로 추구하는 목표이다.

그러나 유한한 개수의 데이터만 관찰해서 모집단의 분포를 정확하게 알아낸다는 것은 불가능하다. 그래서 근사적으로 확률분포를 추정할 수 밖에 없다.

데이터가 특정 확률분포를 따른다고 선험적으로 가정한 후 그 분포를 결정하는 모수를 추정하는 방법을 모수적 방법론이라고 한다

* 평균과 분산을 묶어서 모수라고 한다.

특정 확률분포를 가정하지 않고 데이터에 따라 모델의 구조 및 모수의 개수가 유연하게 바뀌면 비모수 방법론이라 부른다.

* 머신러닝은 대부분 비모수 방법론을 적용한다.
* 비모수 방법론은 모수가 없는 것이 아니라, 모수가 무수히 많거나 데이터에 따라 바뀌는 것을 말한다.



### 확률분포 가정하기

확률분포를 가정하는 방법 : 히스토그램을 통해 모양을 관찰하기

* 데이터가 2개의 값을 가지는 경우 : 베르누이
* 데이터가 n개의 이산적인 값을 가지는 경우 : 카테고리
* 데이터가 \[0, 1\] 사이에서 값을 가지는 경우 : 베타
* 데이터가 0이상의 값을 가지는 경우 : 감마, 로그정규
* 데이터가 실수 전체에서 값을 가지는 경우 : 정규, 라플라스

주의할 점은, 기계적으로 확률분포를 가정해서는 안되며 데이터를 생성하는 원리를 먼저 고려하는 것이 원칙이다.

* 모수를 유추한 뒤에 통계적 검층을 거쳤는지 확인하는 것이 중요



### 데이터로 모수 추정하기

![](../../../../.gitbook/assets/image%20%28747%29.png)

* 통계량의 확률분포를 표집분포라 부르며, 특히 표본평균의 표집분포는 N이 커질수록 정규분포를 따른다
  * sampling distribution과 sample distribution은 다른 개념
  * 따라서 통계량의 확률분포가 N이 커질수록 정규분포를 따르는 것이지 표본에 대한 분포는 그렇지 않다



### 최대가능도 추정법

* 표본평균이나 표본분산은 중요한 통계량이지만 확률분포마다 사용하는 모수가 다르므로 적절한 통계량이 달라지게 된다
* 이론적으로 가장 가능성이 높은 모수를 추정하는 방법 중 하나는 최대가능도 추정법\(maximumlikelihoodestimation,MLE\) 이다.

![](../../../../.gitbook/assets/image%20%28754%29.png)

* 여기서 L은 확률밀도함수나 확률질량함수 같은 것이다. 다만 관점의 차이가 있다.
  * 확률밀도함수나 확률질량함수는 theta가 주어졌을 때 x에 대한 함수로 해석
  * 가능도 함수 L은 변수 theta에 대한 함수로 해석한다
  * 모수 theta에 대한 함수가 x를 관찰하게 된다.
* 데이터 집합 X가 독립적으로 추출되었을 경우 함수들의 곱으로 표현할 수 있다.
  * 로그함수를 이용해서 곱을 덧셈으로 바꾼다.
  * 로그가능도를 최적화 할 때 덧셈의 식으로 이루어진 식을 할 수 있게된다.



### 로그가능도의 필요성

* 로그가능도를 최적화하는 모수 Theta는 가능도를 최적화하는 MLE가 된다.
* 데이터의 숫자가 수억 단위로 많아질수록 컴퓨터의 정확도로 가능도를 계산하는 것이 불가능하다
* 데이터가 독립일 경우 로그를 사용하면 가능도의 곱셈을 덧셈으로 바꿀 수 있기 때문에 컴퓨터로 연산이 가능해진다
* 경사하강법으로 기능도를 최적화 할 때 미분연산을 사용하게 되는데 로그 가능도를 사용하면 연산량은 O\(N^2\) 에서 O\(N\)으로 줄여준다.
* 대게의 손실함수의 경우 경사하강법을 사용하므로 음의 로그가능도를 최적화하게 된다.





