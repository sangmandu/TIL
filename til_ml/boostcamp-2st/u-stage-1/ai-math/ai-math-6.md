---
description: '210805'
---

# \(AI Math 6강\) 확률론 맛보기

### 딥러닝에서 확률론의 필요성

* 딥러닝은 확률론 기반의 기계학습 이론에 바탕을 두고 있다.
* 기계학습에서 사용되는 손실함수들의 작동 원리는 데이터 공간을 통계적으로 해석해서 유도하게 된다.
* 회귀분석에서 손실함수로 사용되는 L2-노름은 예측오차의 분산을가장 최소화하는 방향으로 학습하도록 유도한다
* 분류문제에서 사용되는 교차엔트로피\(cross-entropy\)는 모델예측의 불확실성을 최소화하는방향으로 학습하도록유도한다
* 분산 및 불확실성을 최소화하기 위해서는 측정하는 방법을 알아야 한다



### 이산확률변수 vs 연속확률변수

확률변수는 확률분포에 따라 이산형과 연속형 확률변수로 구분된다.

이산형 확률변수

* 확률변수가 가질 수 있는 모든 경우의 수를 모두 고려하여 확률을 더해서 모델링한다
* 이를 확률질량함수라고 한다.

![](../../../../.gitbook/assets/image%20%28745%29.png)

연속형 확률변수

* 데이터 공간에 정의된 확률변수의 밀도위에서의 적분을 통해 모델링한다
* 이를 확률밀도함수라고 한다.

![](../../../../.gitbook/assets/image%20%28757%29.png)



### 확률 분포

* 데이터 공간을 $$ x \times y $$ 라 표기하고 $$ D $$ 는 데이터공간에서 데이터를 추출하는 분포이다.
* 데이터는 확률변수로 $$ (x, y) $$ ~  $$ D $$라 표기
* 결합분포 P\(x, y\)는 D를 모델링한다
* P\(x\)는 입력 x에 대한 주변확률분포이다.
  * y에대한 정보는 주지 않는다
* 조건부확률 P\(x\|y\)는 데이터 공간에서 입력 x와 출력 y사이의 관계를 모델링한다.



### 조건부확률

* 조건부확률 P\(y\|x\)는 입력변수 x에 대해 정답이 y일 확률이다.
* 로지스틱회귀에서 사용했던 선형모델과 소프트맥스 함수의 결합은 데이터에서 추출된 패턴을 기반으로 확률을 해석하는데 사용된다.
* 분류문제에서 소프트맥스는 데이터 x로부터 추출된 특징패턴 $$ \phi(x) $$과 가중치 행렬 W를 통해 조건부확률 P\(y\|x\)를 계산한다.



### 기대값

* 확률분포가 주어지면 데이터를 분석하는 데 사용 가능한 여러 종류의 통계적 범함수를 계산할 수 있다.
  * 범함수란 함수들의 집합을 정의역으로 갖는함수
  * 통계적 범함수를 계산한다는 것은 통계함수들을 기대값을 통해 사용할 수 있다라는 뜻인것 같다
* 평균의 개념과 동일하다
* 기대값은 데이터를 대표하는 통계량이면서 동시에 확률분포를 통해 다른 통계적 범함수를 계산하는데 사용된다.



### 몬테카를로 샘플링

기계학습의 많은 문제들은 확률분포를 명시적으로 모를 때가 대부분이다. 이럴 때 데이터를 이용하여 기대값을 계산해야 한다. 이러한 방법 중 하나가 몬테카를로 샘플링 방법이다.

![](../../../../.gitbook/assets/image%20%28744%29.png)

* 독립추출이 보장되면 대수의 법칙에 의해 수렴성을 보장한다.







