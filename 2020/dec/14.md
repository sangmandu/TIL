---
description: TIL
---

# 14 Mon

## 결정

 적어도 배운 것을 기록은 해야 TIL의 의미가 있는 것 같다. 하지만 남들이 보기에 매우 자세한 내용이 아니고, 많은 수식과 글 대신 이를 담은 하나의 이미지로 대체 하더라도 이러한 방식을 채택해 작성하기로 한다. TIL에 너무 많은 시간을 투자하지 않고 싶다. 하지만 잘은 쓰고 싶다. 최대한 잘 정리는 할 것.

## 프로그래머스 AI 스쿨 1기

#### 3주차 DAY 1

![](../../.gitbook/assets/image%20%2871%29.png)

### Git이란 무엇인가?

 여러명이서 협업하면서 코드를 작성할 때 이메일등을 사용하기에는 서로의 작업 순서가 고려되어야 되고 앞사람의 완료 시간에 영향을 받는다. 분산 버전관리 시스템 GIT의 등장.

 Git은 분산 버전 관리 시스템! 서버의 원격 저장소에 데이터를 두고 각 구성원의 저장소에서 데이터를 관리 및 추합.

![](../../.gitbook/assets/image%20%2853%29.png)

 `git init`  

 git repositary를 생성한다. 실제로 아무 변화가 없는 것처럼 보이지만 .git 숨김파일에 존재하고 있음.

![](../../.gitbook/assets/image%20%2861%29.png)

* 로컬은 다음과 같이 3가지의 공간으로 구분되어 있음.
* Working Directory는 unstaged 라고도 불리며 commit에 반영되지 않은 부분이 저장되어 있음.
* add라는 행위는 다음에 커밋할 내용을 추가
* commit은 스냅샷할 내용에 적용하며 committed 상태로 바뀜

  `git status`

 현재 branch의 파일들의 상태를 출력

 `git add <추가 파일>`

 커밋에 반영할 파일을 지정 : unstaged -&gt; staged

`git commit -m <메시지>`

 커밋을 남기겠다는 명령어이며 -m 옵션을 붙이면 해당 메시지를 커밋 기록으로 남길 수 있다.

`git log`

커밋에 대한 기록을 열람

### Git branch

 코드의 흐름을 분리하고 분기를 세우는 것. 기본적으로 "master" branch가 존재한다.

`git branch <branch_name>`

branch\_name을 가진 새로운 branch를 생성하는 명령어.

`git branch -v`

 현재 존재하는 branch를 출력

 `git log`

 존재하는 branch를 열람

 `git checkout <branch_name>`

 branch를 전환하는 명령어

`HEAD -> branch`

 현재 작업중인 branch를 의미

`git merge <branch_name> (HEAD -> master)`

 해당 브랜치를 HEAD 브랜치와 병합한다. 

`git branch -d <branch_name>`

 해당 브랜치를 삭제한다.

### Git과 Git hub

`git remote add <별칭> <원격저장소 주소>`

 원격 저장소를 지정하는 명령어. 별칭에는 보통 origin을 많이 사용한다.

`git remote -v`

 원격 저장소의 목록을 보여준다.

`git push <remote_repo_name> <branch_name>`

 로컬 저장소의 내용을 원격 저장소의 내용으로 전송한다.

`git branch -M main`

 브랜치의 이름을 변경하며 -M의 인자가 한개일 경우 현재 브랜치의 이름을 해당 인자로 변경한다.

 `git clone <remote_repo> <directory_name>`

 원격저장소를 로컬저장소로 불러오는 명령이다. remote\_repo는 원격저장소의 주소이며 directory\_name이 없을 경우 default로 원격저장소의 폴더 이름으로 지정된다.

###  1강 Numpy의 연산

![](../../.gitbook/assets/image%20%2860%29.png)

![](../../.gitbook/assets/image%20%2872%29.png)

![](../../.gitbook/assets/image%20%2854%29.png)

![](../../.gitbook/assets/image%20%2865%29.png)

![](../../.gitbook/assets/image%20%2857%29.png)

### 2강 Numpy와 선형대수

![](../../.gitbook/assets/image%20%2873%29.png)

![](../../.gitbook/assets/image%20%2868%29.png)

![](../../.gitbook/assets/image%20%2858%29.png)

이 때, eye의 default type은 float이다.

![](../../.gitbook/assets/image%20%2866%29.png)

![](../../.gitbook/assets/image%20%2869%29.png)

![](../../.gitbook/assets/image%20%2864%29.png)

![](../../.gitbook/assets/image%20%2856%29.png)

 역행렬이 없을 경우 Singular matrix 오류가 발생한다.

![](../../.gitbook/assets/image%20%2863%29.png)

![](../../.gitbook/assets/image%20%2855%29.png)

![](../../.gitbook/assets/image%20%2859%29.png)



## 밑바닥부터 시작하는 딥러닝

###  4장 신경망 학습

 학습 : 훈련 데이터로부터 가중치 매개변수의 최적값을 자동으로 획득하는 것

###  4.1 데이터에서 학습한다!

 신경망의 특징 : 데이터를 보고 학습. 즉, 데이터를 자동으로 결정. 이것이 퍼셉트론과의 차이이다. \(퍼셉트론 수렴 정리에 따르면 선형 분리 가능 문제는 유한 번의 학습을 통해 풀 수 있다. 그러나 비선형 분리 문제는 자동으로 학습이 불가능하다.\)

 손글씨 숫자 '5'를 제대로 분류하는 프로그램을 설계하는 것은 어렵다. 사람은 어렵지 않게 인식하지만, 규칙성을 명확한 로직으로 표현하기가 어렵기 때문. 따라서 설계하는 대신 데이터의 특징의 패턴을 학습. 컴퓨터 비전 분야에서는 SIFT, SURF, HOG 등의 특징을 많이 사용하며, SVM, KNN 등으로 학습한다.

**SIFT**

{% embed url="https://bskyvision.com/144" %}

{% embed url="https://bskyvision.com/21" %}

 초기에 사람이 생각한 알고리즘으로 결과가 도출된다면 이후에는 사람이 생각한 특징\(SIFT, HOG 등\)을 통해 기계 학습\(SVM, KNN 등\)으로 결과가 도출된다. 최종적으로 신경망은 이미지를 있는 그대로 학습한다. 사람이 특징을 설계하는 것이 아닌, 기계 스스로 특징을 학습한다. 이를 종단간 기계학습 이라고도 하며 입력부터 출력까지 사람의 개입이 없다는 의미이다.

 기계 학습은 데이터를 훈련 데이터와 시험 데이터로 나눠 학습과 실험을 수행한다. 이 때 범용 능력을 위해 두 데이터로 분리하는 것. 범용 능력은 아직 보지 못한 데이터 문제를 올바르게 풀어내는 능력이다. 한 데이터셋으로만 학습과 평가를 수행하는 것은 올바른 평가가 될 수 없으며 한 데이터셋에만 지나치게 최적화 되어 오버피팅이 발생한다.

###  4.2 손실 함수

 신경망 학습에서는 현재의 상태를 하나의 지표로 표현한다. 그리고 이 지표를 가장 좋게 만들어주는 가중치 매개변수의 값을 탐색한다. 신경망 학습에서 사용하는 지표는 손실 함수라고 하며 일반적으로 평균 제곱 오차와 교차 엔트로피 오차를 사용한다.

 **평균 제곱 오차**

 $$ E ={1\over2} \sum(y_k - t_k)^2 $$

 **교차 엔트로피 오차**

$$E = -\sum\limits_{k} t_k ln y_k$$

 위 식들은 단일 데이터에 대한 손실 함수이며 다 데이터일 경우는 모든 데이터에 대한 손실함수의 값의 합을 지표로 삼는다.

$$E = -{1\over N}\sum\limits_N\sum\limits_{k} t_{nk} ln y_{nk}$$

 마지막에 N으로 나누는 과정을 통해 정규화를 한다. N으로 나눔으로써 '평균 손실 함수'를 구하는 것과 같으며 이는 훈련 데이터 개수와 관계없이 통일된 지표를 얻을 수 있게된다.

 이 때 데이터가 6만개\(또는 그 이상\)라면 모든 데이터의 손실 함수의 합을 구하기는 많은 시간이 소요된다. 이런 경우 일부 데이터를 추려 전체의 '근사치'로 이용한다. 훈련 데이터 중 일부만 골라 학습을 수행하며 이를 **미니 배치** 라고 한다.

이 때 MNIST 데이터셋을 읽어와 6만개의 훈련 데이터중 10개를 뽑는 과정에서 numpy를 사용할 수 있다. 

np.random.choice\(train\_size, batch\_size\)를 사용할 수 있으며, 0이상 train\_size미만의 수 중에서 무작위로 batch\_size 만큼의 갯수의 수를 골라낸다.

 **정확도 대신 손실함수를 정의하는 이유**

 손실함수는 미분값을 토대로 양의 방향 또는 그 반대로 진행하는데 비해 정확도는 미분값이 0일 경우가 많아 진행을 멈출 때가 많다. 그럼 왜 0일 떄가 많을까? 매개변수의 값이 조금 변하면 손실 함수는 연속적으로 변하게 되지만 정확도는 매개변수의 미소한 변화에는 거의 반응을 보이지 않으며 반응이 있더라도 그 값이 불연속적으로 변화한다. 계단 함수를 활성화 함수로 사용하지 않는 이유도 이와 같다.

### 4.3 수치 미분

 아주 작은 차분으로 미분하는 것을 수치 미분이라고 한다. 여기에는 반올림 오차가 발생할 수 있어 최종 계산 결과에 오차가 발생된다.

```python
>>> np.float32(1e-50)
0
```

한 수식을 전개해 미분하는 것은 해석적이라고 하며 $$ y = x^2 $$의 미분은 $$ {dy \over dx} = 2x $$ 로 풀어낼 수 있다. 해석적 미분은 오차를 포함하지 않는 값을 구해준다.

 수치 미분에는 오차가 발생하며 오차를 줄이기 위해 x+h 와 x-h일 때의 차분을 계산하기도 한다. x를 중심으로 그 전후의 차분을 계산한다고 하여 중심 차분 혹은 중앙 차분이라고 한다. x+h와 x의 차분은 전방 차분이라고 한다.

###  4.4 기울기

 변수가 여럿인 함수에 대해 변수가 하나뿐인 함수로 정의해서 구하는 미분을 **편미분**이라고 한다. 이 때 모든 벡터의 편미분을 벡터로 정리한 것을 기울기 라고 한다.







## Coursera ML

### OCTAVE/MATLAB TUTORIAL

![](../../.gitbook/assets/image%20%2862%29.png)

![](../../.gitbook/assets/image%20%2870%29.png)

Normal Equation 에 대한 선형 대수 증명

{% embed url="https://kgwcredit.tistory.com/13" %}

####  강의내용

 옥타브를 이용해서 여러 수학적 연산과 함수를 이용해을 간단히 표현 가능.

![](../../.gitbook/assets/image%20%2867%29.png)

 벡터화하면 간단히 행렬 연산으로 표현할 수 있지만 언벡터화의 경우 반복 연산으로 진행해야한다. 메모리와 속도의 tradeoff를 보여주는 사례인 듯.





